{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b450759-0b63-43dc-aaae-0c552dc742ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#полный пайплайн TEA\n",
    "#изготавливает модель, сохраняет, разбирает, генерит с помощью модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc926f-a841-44cb-b4ef-c98edc2153c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b716ec6b-dd22-4253-afd0-5c8f7f5449ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "install = False\n",
    "#Через requirements поставить это затруднительно, последовательность установки важна, так как часть либ компилируются\n",
    "#Эта последовательность установки, как бы странно она ни выглядела, работает. Не в любых окружениях, но во многих.\n",
    "if install:\n",
    "\n",
    "    !pip install deepspeed==0.14.4\n",
    "\n",
    "    !pip install --upgrade pip\n",
    "    !pip install --upgrade transformers==4.46.2 tyro==0.9.8 triton==2.3.1 trl==0.12.0\n",
    "\n",
    "    !pip install -v \"xformers==0.0.29.post1\"\n",
    "    #!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "    !pip install --no-deps -v \"peft==0.13.2\"\n",
    "    !pip install --no-deps packaging ninja einops flash-attn bitsandbytes==0.44.1\n",
    "    !pip install accelerate==0.34.2\n",
    "    !pip uninstall peft -y\n",
    "    !pip install -v \"peft==0.13.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56dee4c5-5085-485f-b5f4-6f3202afd374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import os, pickle, random\n",
    "import psutil\n",
    "import warnings\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from typing import Dict, List, Optional\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from itertools import chain\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "from torch import cuda, LongTensor, FloatTensor\n",
    "from peft import PeftModel, PeftConfig, PeftModelForCausalLM\n",
    "\n",
    "import ensembles\n",
    "#from sequential_models import GPTAdapterLayer, GPTAdapterLayerWide, assemble_model, disassemble_model\n",
    "import sequential_models\n",
    "from benchmarks import LLMBenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b51f5dc-45af-42fe-b377-275433640215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется GPU с номером: 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Используется GPU с номером: {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83241649-7c80-421c-b139-687028ee1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4ac20d-b48b-432b-8888-1553f76a0a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступен только один GPU (номер 0), переключение невозможно\n"
     ]
    }
   ],
   "source": [
    "# Проверяем доступность CUDA и количество GPU\n",
    "#если надо, можем переключиться на другую GPU\n",
    "if 1:\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:  # Если есть более 1 GPU\n",
    "            device = torch.device(\"cuda:1\")  # Явно указываем устройство 1\n",
    "            print(f\"Переключились на GPU 1\")\n",
    "        else:\n",
    "            print(\"Доступен только один GPU (номер 0), переключение невозможно\")\n",
    "    else:\n",
    "        print(\"CUDA недоступно\")\n",
    "sequential_models.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f152af-ef50-422f-859a-a52c9c27057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining GPU memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "print(f'Remaining GPU memory: {torch.cuda.memory_allocated() / (1024 ** 3):.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff90a212-5828-45ee-87af-82cc907b1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_train = False#Запускаем ли мы сейчас обучение с нуля, или с чекпоинта\n",
    "learnable_linear_model = True#учим ли мы линейную субмодель внутри lm_head\n",
    "\n",
    "\n",
    "cardinality = 128256#размер словаря токенов\n",
    "\n",
    "padding_token = 128009\n",
    "forbidden_tokens_list = [padding_token]\n",
    "seed = int(np.random.rand() * 1000000)#random seed for data sampling\n",
    "\n",
    "bits_per_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccff924-fd63-45f2-a191-8cb83b313b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae93daaf-fbaa-4898-a816-8bf140ba04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_batch_size4loss = 512#1024# * 3#1024 * 2#loss считаем батчами, во избежание out of memory error\n",
    "head_max_batch_size = 1024#lm_head заускаем батчами, во избежание out of memory error\n",
    "\n",
    "# Добавляем параметры для кэширования\n",
    "#'only_train' - просто учимся, как раньше\n",
    "#'only_cache' - не учимся, а кешируем таблицу embedding -> label\n",
    "#'train_from_cache' - учимся, но не запускаем исходную LLM, а берём эмбеддинги из кешей\n",
    "#'train_and_cache' - учимся, как раньше И пишем эмбеддинги (внимание, убедитесь, что ['transformer_update_rate'] = 0, иначе у вас эмбеддинги будут от разных версий трансформерного адаптера)\n",
    "cache_mode = 'train_from_cache'#'only_cache'#'train_from_cache'\n",
    "\n",
    "SAMPLE_PER_FILE = 200000 # Количество примеров в файле кэша\n",
    "#\"D:\\cache\\cache_instruct\"   # Директория для хранения кэша\n",
    "#\"C:\\\\Users\\\\sd\\\\Yandex.Disk\\\\caches_tea\\\\heavy_4\"\n",
    "cache_dir = \"D:\\cache\\cache_instruct\"#\"D:\\cache\\c_test\"#\"D:\\cache\\cache_instruct\"\n",
    "if cache_mode == 'only_train':\n",
    "    generate_cache = False  # Генерировать кэш эмбеддингов\n",
    "    train_anything = True  # Генерировать кэш эмбеддингов\n",
    "    use_cache = False       # Использовать существующий кэш\n",
    "elif cache_mode == 'only_cache':\n",
    "    generate_cache = True  # Генерировать кэш эмбеддингов\n",
    "    train_anything = False  # Генерировать кэш эмбеддингов\n",
    "    use_cache = False       # Использовать существующий кэш\n",
    "elif cache_mode == 'train_from_cache':\n",
    "    generate_cache = False  # Генерировать кэш эмбеддингов\n",
    "    train_anything = True  # Генерировать кэш эмбеддингов\n",
    "    use_cache = True       # Использовать существующий кэш\n",
    "elif cache_mode == 'train_and_cache':\n",
    "    generate_cache = True  # Генерировать кэш эмбеддингов\n",
    "    train_anything = True  # Генерировать кэш эмбеддингов\n",
    "    use_cache = True       # Использовать существующий кэш\n",
    "else:\n",
    "    1/0\n",
    "\n",
    "use_cp_for_head = True#если True, то мы более устойчивы к OOM, если false, то быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e3204a-6817-4fde-b2be-7f327cc8fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#конфигурации моделек\n",
    "mode = 'finetune'#'finetune', 'pretrain'\n",
    "model_version = \"heavy_4\"#\"light_1\"#\"heavy_4\"\n",
    "transformer_adapter_params = {}\n",
    "lm_head_adapter_params = {'cardinality':cardinality}\n",
    "optimizer_params = {}\n",
    "depth2freeze = 0\n",
    "if model_version == \"heavy_2\":\n",
    "    transformer_adapter_params['embed_dim'] = 4096\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "    #трансформерный адаптер\n",
    "    transformer_adapter_params['num_heads_tlayer'] = 16\n",
    "    transformer_adapter_params['ff_dim'] = transformer_adapter_params['embed_dim']  * 4\n",
    "    transformer_adapter_params['t_layers_count'] = 2\n",
    "    transformer_adapter_params['layer_configs'] = [1024*4] * 2\n",
    "    optimizer_params['batch_size'] = 1#почему-то распараллеливание ухудшает скорость, а так щдесь можно поставить и другое число\n",
    "    optimizer_params['accum_batch'] = 50\n",
    "    optimizer_params['lr'] = 1e-6#lr для LM_head\n",
    "    optimizer_params['lr_transformer'] = optimizer_params['lr'] * 0.05#lr для трансформерного адаптера\n",
    "    optimizer_params['transformer_update_rate'] = 0.5#0.2#доля случаев, когда через трансформерный адаптер реально идут градиенты. Влияет на быстродействие\n",
    "    transformer_adapter_params['transformer_adapter_weight'] = 1e-3#идея в том, что со старта адаптерный слой должен влиять совсем чуть-чуть\n",
    "    transformer_adapter_params['dropout'] = 0.1\n",
    "    transformer_adapter_params['concat'] = False\n",
    "    optimizer_params['opt_type'] = 'adam'\n",
    "\n",
    "    #адаптер для LM-head\n",
    "    lm_head_adapter_params['embedding_size'] = transformer_adapter_params['embed_dim']\n",
    "    lm_head_adapter_params['heavy_head'] = True\n",
    "    lm_head_adapter_params['net_dropout_rate'] = 0\n",
    "    lm_head_adapter_params['individ_dropout_rate'] = 0.03\n",
    "    lm_head_adapter_params['layer_configs_head'] = [2048] * 5 + [1024] * 5\n",
    "    lm_head_adapter_params['sample_features'] = 1\n",
    "    lm_head_adapter_params['composition_size'] = 1\n",
    "    lm_head_adapter_params['memnet_params'] = {}\n",
    "    lm_head_adapter_params['use_memnets'] = False\n",
    "\n",
    "\n",
    "\n",
    "elif model_version == \"heavy_3\":\n",
    "    transformer_adapter_params['embed_dim'] = 4096\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "    #трансформерный адаптер\n",
    "    transformer_adapter_params['num_heads_tlayer'] = 32\n",
    "    transformer_adapter_params['ff_dim'] = transformer_adapter_params['embed_dim']  * 2\n",
    "    transformer_adapter_params['t_layers_count'] = 1\n",
    "    transformer_adapter_params['layer_configs'] = [1024*4] * 4\n",
    "    optimizer_params['batch_size'] = 1#почему-то распараллеливание ухудшает скорость, а так щдесь можно поставить и другое число\n",
    "    optimizer_params['accum_batch'] = 13000\n",
    "    optimizer_params['lr'] = 1e-7#lr для LM_head\n",
    "    optimizer_params['transformer_update_rate'] = 0.#0.2#доля случаев, когда через трансформерный адаптер реально идут градиенты. Влияет на быстродействие\n",
    "    optimizer_params['lr_transformer'] = optimizer_params['lr'] * 0.1 * optimizer_params['transformer_update_rate']#lr для трансформерного адаптера\n",
    "    transformer_adapter_params['transformer_adapter_weight'] = 1e-3#идея в том, что со старта адаптерный слой должен влиять совсем чуть-чуть\n",
    "    transformer_adapter_params['dropout'] = 0.1\n",
    "    transformer_adapter_params['concat'] = True\n",
    "    optimizer_params['opt_type'] = 'adam'\n",
    "\n",
    "    #адаптер для LM-head\n",
    "    lm_head_adapter_params['embedding_size'] = transformer_adapter_params['embed_dim']\n",
    "    lm_head_adapter_params['heavy_head'] = True\n",
    "    lm_head_adapter_params['net_dropout_rate'] = 0\n",
    "    lm_head_adapter_params['individ_dropout_rate'] = 0.03\n",
    "    lm_head_adapter_params['layer_configs_head'] = [2048] * 6 + [1024] * 5\n",
    "    lm_head_adapter_params['sample_features'] = 1\n",
    "    lm_head_adapter_params['composition_size'] = 1\n",
    "    lm_head_adapter_params['memnet_params'] = {}\n",
    "    lm_head_adapter_params['use_memnets'] = False\n",
    "\n",
    "elif model_version == \"heavy_3_1\":\n",
    "    transformer_adapter_params['embed_dim'] = 4096\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "    #трансформерный адаптер\n",
    "    transformer_adapter_params['num_heads_tlayer'] = 32\n",
    "    transformer_adapter_params['ff_dim'] = transformer_adapter_params['embed_dim']  * 2\n",
    "    transformer_adapter_params['t_layers_count'] = 1\n",
    "    transformer_adapter_params['layer_configs'] = [1024*4] * 4\n",
    "    optimizer_params['batch_size'] = 2#почему-то распараллеливание ухудшает скорость, а так щдесь можно поставить и другое число\n",
    "    optimizer_params['accum_batch'] = 8000\n",
    "    optimizer_params['lr'] = 5e-7#lr для LM_head\n",
    "    optimizer_params['transformer_update_rate'] = 0.#0.2#доля случаев, когда через трансформерный адаптер реально идут градиенты. Влияет на быстродействие\n",
    "    optimizer_params['lr_transformer'] = optimizer_params['lr'] * 0.1 * optimizer_params['transformer_update_rate']#lr для трансформерного адаптера\n",
    "    transformer_adapter_params['transformer_adapter_weight'] = 1e-3#идея в том, что со старта адаптерный слой должен влиять совсем чуть-чуть\n",
    "    transformer_adapter_params['dropout'] = 0.1\n",
    "    transformer_adapter_params['concat'] = True\n",
    "    optimizer_params['opt_type'] = 'adam'\n",
    "\n",
    "    #адаптер для LM-head\n",
    "    lm_head_adapter_params['embedding_size'] = transformer_adapter_params['embed_dim']\n",
    "    lm_head_adapter_params['heavy_head'] = True\n",
    "    lm_head_adapter_params['net_dropout_rate'] = 0\n",
    "    lm_head_adapter_params['individ_dropout_rate'] = 0.03\n",
    "    lm_head_adapter_params['layer_configs_head'] = [2048] * 6 + [1024] * 5\n",
    "    lm_head_adapter_params['sample_features'] = 1\n",
    "    lm_head_adapter_params['composition_size'] = 1\n",
    "    lm_head_adapter_params['memnet_params'] = {}\n",
    "    lm_head_adapter_params['use_memnets'] = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "elif model_version == \"heavy_4\":\n",
    "    transformer_adapter_params['embed_dim'] = 4096\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "    #трансформерный адаптер\n",
    "    transformer_adapter_params['num_heads_tlayer'] = 32\n",
    "    transformer_adapter_params['ff_dim'] = transformer_adapter_params['embed_dim']  * 2\n",
    "    transformer_adapter_params['t_layers_count'] = 1\n",
    "    transformer_adapter_params['layer_configs'] = [1024*4] * 10\n",
    "    optimizer_params['batch_size'] = 1#2#почему-то распараллеливание ухудшает скорость, а так щдесь можно поставить и другое число\n",
    "    optimizer_params['accum_batch'] = 300#500#23000#10000\n",
    "    optimizer_params['lr'] = 1e-6#lr для LM_head\n",
    "    optimizer_params['transformer_update_rate'] = 0#0.2#доля случаев, когда через трансформерный адаптер реально идут градиенты. Влияет на быстродействие\n",
    "    optimizer_params['lr_transformer'] = optimizer_params['lr'] * 0.1 * optimizer_params['transformer_update_rate']#lr для трансформерного адаптера\n",
    "    \n",
    "    transformer_adapter_params['transformer_adapter_weight'] = 1e-3#идея в том, что со старта адаптерный слой должен влиять совсем чуть-чуть\n",
    "    transformer_adapter_params['dropout'] = 0.1\n",
    "    transformer_adapter_params['concat'] = True\n",
    "    optimizer_params['opt_type'] = 'adam'#'adam'\n",
    "    \n",
    "    #адаптер для LM-head\n",
    "    lm_head_adapter_params['embedding_size'] = transformer_adapter_params['embed_dim']\n",
    "    lm_head_adapter_params['heavy_head'] = True\n",
    "    # lm_head_adapter_params['net_dropout_rate'] = 0.\n",
    "    # lm_head_adapter_params['individ_dropout_rate'] = 0.03\n",
    "    # lm_head_adapter_params['layer_configs_head'] = [1024 * 2] * 2 + [512] * 3#[1024 * 3] * 2 + [1024] + [512]\n",
    "    # lm_head_adapter_params['sample_features'] = 1.\n",
    "    # lm_head_adapter_params['composition_size'] = 1\n",
    "\n",
    "    lm_head_adapter_params['net_dropout_rate'] = 0.1\n",
    "    lm_head_adapter_params['individ_dropout_rate'] = 0.03\n",
    "    lm_head_adapter_params['layer_configs_head'] = [256] * 2 + [128] * 3 + [64] * 3#[512] * 2 + [256] * 3 + [128] * 3#[1024 * 3] * 2 + [1024] + [512]\n",
    "    lm_head_adapter_params['sample_features'] = 0.95\n",
    "    lm_head_adapter_params['composition_size'] = 6\n",
    "\n",
    "\n",
    "    # lm_head_adapter_params['net_dropout_rate'] = 0.7\n",
    "    # lm_head_adapter_params['individ_dropout_rate'] = 0.03\n",
    "    # lm_head_adapter_params['layer_configs_head'] = [256] * 2 + [128] * 2 + [64] * 2#[1024 * 3] * 2 + [1024] + [512]\n",
    "    # lm_head_adapter_params['sample_features'] = 0.85\n",
    "    # lm_head_adapter_params['composition_size'] = 14\n",
    "    \n",
    "    lm_head_adapter_params['memnet_params'] = {}\n",
    "    lm_head_adapter_params['use_memnets'] = False\n",
    "\n",
    "\n",
    "    lm_head_adapter_params['recreate_lm_head'] = False\n",
    "    \n",
    "\n",
    "    depth2freeze = 0#32#28\n",
    "\n",
    "elif model_version == \"light_1\":\n",
    "    #размерность \"родного\" трансформера\n",
    "    transformer_adapter_params['original_transformer_size'] = 2048\n",
    "    #размерность адаптера! Может не совпадать с размерностью \"родного\" трансформера\n",
    "    transformer_adapter_params['embed_dim'] = 2048\n",
    "    model_name = \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\"\n",
    "    #трансформерный адаптер\n",
    "    transformer_adapter_params['num_heads_tlayer'] = 32\n",
    "    transformer_adapter_params['ff_dim'] = transformer_adapter_params['embed_dim']  * 2\n",
    "    transformer_adapter_params['t_layers_count'] = 2\n",
    "    transformer_adapter_params['layer_configs'] = [1024*2] * 10\n",
    "    optimizer_params['batch_size'] = 1#почему-то распараллеливание ухудшает скорость, а так здесь можно поставить и другое число\n",
    "    optimizer_params['accum_batch'] = 100#10000\n",
    "    optimizer_params['lr'] = 1e-6#lr для LM_head\n",
    "    optimizer_params['transformer_update_rate'] = 1.#0.2#доля случаев, когда через трансформерный адаптер реально идут градиенты. Влияет на быстродействие\n",
    "    optimizer_params['lr_transformer'] = optimizer_params['lr'] * 0.1 * optimizer_params['transformer_update_rate']#lr для трансформерного адаптера\n",
    "    \n",
    "    transformer_adapter_params['transformer_adapter_weight'] = 1e-3#идея в том, что со старта адаптерный слой должен влиять совсем чуть-чуть\n",
    "    transformer_adapter_params['dropout'] = 0.1\n",
    "    transformer_adapter_params['concat'] = True\n",
    "    transformer_adapter_params['wide'] = True\n",
    "\n",
    "    optimizer_params['opt_type'] = 'adam'#'adam'\n",
    "\n",
    "    #адаптер для LM-head \n",
    "    lm_head_adapter_params['heavy_head'] = True\n",
    "    #Ну типа исходный трансформер + все слои адаптера через конкат\n",
    "    lm_head_adapter_params['embedding_size'] = transformer_adapter_params['embed_dim'] * transformer_adapter_params['t_layers_count'] + transformer_adapter_params['original_transformer_size']\n",
    "    lm_head_adapter_params['net_dropout_rate'] = 0\n",
    "    lm_head_adapter_params['individ_dropout_rate'] = 0.03\n",
    "    lm_head_adapter_params['layer_configs_head'] = [1024 * 3] * 4 + [1024 * 2] * 2 + [1024 * 1] * 8\n",
    "    lm_head_adapter_params['sample_features'] = 1\n",
    "    lm_head_adapter_params['composition_size'] = 1\n",
    "    lm_head_adapter_params['memnet_params'] = {}\n",
    "    lm_head_adapter_params['use_memnets'] = False\n",
    "\n",
    "    depth2freeze = 0\n",
    "\n",
    "\n",
    "elif model_version == \"light_2\":\n",
    "    transformer_adapter_params['embed_dim'] = 2048\n",
    "    model_name = \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\"\n",
    "    #трансформерный адаптер\n",
    "    transformer_adapter_params['num_heads_tlayer'] = 32\n",
    "    transformer_adapter_params['ff_dim'] = transformer_adapter_params['embed_dim']  * 2\n",
    "    transformer_adapter_params['t_layers_count'] = 2\n",
    "    transformer_adapter_params['layer_configs'] = [1024*4] * 8\n",
    "    optimizer_params['batch_size'] = 1#почему-то распараллеливание ухудшает скорость, а так щдесь можно поставить и другое число\n",
    "    optimizer_params['accum_batch'] = 1000#10000\n",
    "    optimizer_params['lr'] = 1e-6#lr для LM_head\n",
    "    optimizer_params['transformer_update_rate'] = 0.#0.2#доля случаев, когда через трансформерный адаптер реально идут градиенты. Влияет на быстродействие\n",
    "    optimizer_params['lr_transformer'] = optimizer_params['lr'] * 0.1 * optimizer_params['transformer_update_rate']#lr для трансформерного адаптера\n",
    "    \n",
    "    transformer_adapter_params['transformer_adapter_weight'] = 1e-4#идея в том, что со старта адаптерный слой должен влиять совсем чуть-чуть\n",
    "    transformer_adapter_params['dropout'] = 0.1\n",
    "    transformer_adapter_params['concat'] = True\n",
    "    optimizer_params['opt_type'] = 'adam'#'adam'\n",
    "\n",
    "    #адаптер для LM-head\n",
    "    lm_head_adapter_params['embedding_size'] = transformer_adapter_params['embed_dim']\n",
    "    lm_head_adapter_params['heavy_head'] = True\n",
    "    lm_head_adapter_params['net_dropout_rate'] = 0\n",
    "    lm_head_adapter_params['individ_dropout_rate'] = 0.03\n",
    "    lm_head_adapter_params['layer_configs_head'] = [1024 * 4] * 7 + [1024 * 2] * 8\n",
    "    lm_head_adapter_params['sample_features'] = 1\n",
    "    lm_head_adapter_params['composition_size'] = 1\n",
    "    lm_head_adapter_params['memnet_params'] = {}\n",
    "    lm_head_adapter_params['use_memnets'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c9abcd-c2b0-4e10-9a32-5e516e321c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_head_adapter_params['head_max_batch_size'] = head_max_batch_size\n",
    "lm_head_adapter_params['learnable_linear_model'] = learnable_linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe3c61a7-a882-40ae-bf7e-65b844fd0469",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2tadapter = f\"tadapter_{model_version}.pth\"\n",
    "path2lmhead = f\"lmhead_{model_version}.pth\"\n",
    "tokenizer_name = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "211d07a1-531e-46f1-9aa1-ecd890e6704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#настройки датасета\n",
    "\n",
    "max_loss_len = 5000#столько токенов можно пихать в Y, не больше\n",
    "if mode == 'pretrain':\n",
    "    #претрейн\n",
    "    max_seq_len4inference = 6850#в X и в Y можно пихать столько токенов, в каждый. Не больше.\n",
    "else:\n",
    "    #дообучение\n",
    "    #max_seq_len4inference = 6850\n",
    "    max_seq_len4inference = 5050\n",
    "    #max_seq_len4inference = 4450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01a99486-1f3f-4b83-b57a-88fe00ee0c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['device_map']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "You shouldn't move a model that is dispatched using accelerate hooks.\n"
     ]
    }
   ],
   "source": [
    "#Загрузили исходную модельку\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)#, cache_dir=\"D:\\cache\\huggingface\\\\\"+ model_name)\n",
    "\n",
    "if bits_per_number == 4:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", device_map={\"\": device} #, bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "elif bits_per_number == 8:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True, bnb_8bit_use_double_quant=True, bnb_8bit_quant_type=\"nf8\", device_map={\"\": device} #, bnb_8bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "else:\n",
    "    bnb_config = None\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "              model_name,\n",
    "              quantization_config=bnb_config,\n",
    "              cache_dir=\"D:\\cache\\huggingface\\\\\"+ model_name,\n",
    "              device_map={\"\": device},  # Важно! Указываем здесь, а не только в bnb_config\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f308a2e1-93f4-42c1-8ff6-42eb4239c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.lm_head\n",
    "if cache_mode != 'train_from_cache':\n",
    "    torch.save(model.lm_head.weight, \"lin_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bac2e1da-5e9f-4ec9-a3c8-e3f4229ad40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructDatasetR(Dataset):\n",
    "    def __init__(self, data_file, tokenizer, max_seq_length=1000000, cut=None):\n",
    "        self.data_file = data_file\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.cut = cut\n",
    "        self.data = self.load_data()\n",
    "        self.log_samples = deque(maxlen=45)\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.data_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        random.seed(seed)\n",
    "        data = random.sample(data, len(data))\n",
    "        \n",
    "        # if self.cut is None:\n",
    "        #     data = [data_cur for data_cur in data if len(data_cur[1])>5]\n",
    "        # else:\n",
    "        #     data = [data_cur for data_cur in data[:self.cut] if self.cut>5]\n",
    "        # for i in range(100):\n",
    "        #     print('***', data[i])\n",
    "        #     try:\n",
    "        #         if (not 'Алис' in data[i][0]) and (not 'Элеон\"' in data[i][0]) and (not 'Софи\"' in data[i][0]) and (not 'Сэм\"' in data[i][0]) (not 'Алис' in data[i][1]) and (not 'Элеон\"' in data[i][1]) and (not 'Софи\"' in data[i][1]) and (not 'Сэм\"' in data[i][1]):\n",
    "        #             print('***', data[i])\n",
    "        #     except Exception:\n",
    "        #         pass\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        self.log_samples.append(self.data[idx])\n",
    "        parts = self.data[idx]\n",
    "        text = parts[0]\n",
    "        label = parts[1]\n",
    "        parts = [parts[0], parts[1], 1]\n",
    "        for r_variant in [-2,-1,-0.5,0.5,1,2]:\n",
    "            s = f\"<r{r_variant}>\"\n",
    "            if s in label:\n",
    "                parts[-1] = r_variant\n",
    "                label = label.replace(s, '')\n",
    "                break\n",
    "        r = parts[-1]\n",
    "        if text is None:\n",
    "            text = label\n",
    "        \n",
    "        # Кодируем текст и метку с помощью tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            max_length=self.max_seq_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        \n",
    "        # Кодируем метку\n",
    "        label_encoding = self.tokenizer.encode_plus(\n",
    "            label,\n",
    "            max_length=self.max_seq_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        label_ids = label_encoding['input_ids']\n",
    "        return {\n",
    "            'input_ids': input_ids[0],\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label_ids[0],\n",
    "            'mult': torch.tensor(r)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e8a7526-ec4c-40b7-8320-4a469f360318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание Dataset\n",
    "#такая конструкция нужна на случай, что вы загружаете датасет на диск, сейчас час ночи, \n",
    "#датасет догрузится примерно через час, а завтра вам рано вставать\n",
    "#с таким подходм код будет выполняться, когда найдёт на диске датасет\n",
    "if not use_cache:\n",
    "    while 1:\n",
    "        try:\n",
    "            if mode == 'pretrain':\n",
    "                #dataset = InstructDatasetR(\"./data/dataset_llm_full_mflat.pkl\", tokenizer, max_seq_len, cut=None)\n",
    "                dataset = InstructDatasetR(\"../llms_local/dataset_llm_full_flat.pkl\", tokenizer, max_seq_length=1000000, cut=None)\n",
    "            else:\n",
    "                dataset = InstructDatasetR(\"../llms_local/dataset_llm_full_instruct.pkl\", tokenizer, max_seq_length=1000000, cut=None)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e, pd.Timestamp.now())\n",
    "            time.sleep(10)\n",
    "    len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00128664-8ce8-48d9-bf3e-ba7fb99ad2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_clip(tens, mn, mx):\n",
    "    mn = torch.tensor(mn).to(tens.device)\n",
    "    mx = torch.tensor(mx).to(tens.device)\n",
    "    tens[tens<mn] = torch.nn.Sigmoid()(tens[tens<mn]) + mn\n",
    "    tens[tens>mx] = torch.nn.Sigmoid()(tens[tens>mx]) + mx\n",
    "    return tens\n",
    "# Функция для подсчёта количества последних токенов, равных padding_token\n",
    "def count_padding(tensor, padding_token):\n",
    "    counts = []\n",
    "    for row in tensor:\n",
    "        count = 0\n",
    "        for token in reversed(row):\n",
    "            if token.item() == padding_token:\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "        counts.append(count)\n",
    "    return min(counts)\n",
    "def count_trainable_parameters(model: nn.Module) -> tuple[int, int]:\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    frozen = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    return trainable, frozen\n",
    "loss_fct = nn.CrossEntropyLoss(reduction = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d252c6c-567b-4166-a38c-be91a3d05abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "882c53b2-f9ce-41f6-b485-f6aafb22340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#теперь сохранение адаптеров\n",
    "def save_adapters(head, tadapter, path2lmhead, path2tadapter):\n",
    "    head.training = False\n",
    "    torch.save(head, path2lmhead)\n",
    "    if path2tadapter is not None:\n",
    "        torch.save(tadapter, path2tadapter)\n",
    "    head.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dfef2eb-45c5-46e2-ac7a-93981027dfa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tadapter\n",
      "loading heavy LM head\n",
      "Head. Обучаемые: 1,377,887,616\n",
      "Замороженные: 0\n",
      "Transformer adapter. Обучаемые: 0\n",
      "Замороженные: 373,848,393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EResNetPro(\n",
       "  (lin_model_add): Linear(in_features=4096, out_features=128256, bias=True)\n",
       "  (submodels): ModuleList(\n",
       "    (0): ResNet(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=7783, out_features=256, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Dropout(p=0.03, inplace=False)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (5): Sigmoid()\n",
       "        (6): Dropout(p=0.03, inplace=False)\n",
       "        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (9): Sigmoid()\n",
       "        (10): Dropout(p=0.03, inplace=False)\n",
       "        (11): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (12): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (13): Sigmoid()\n",
       "        (14): Dropout(p=0.03, inplace=False)\n",
       "        (15): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (16): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (17): Sigmoid()\n",
       "        (18): Dropout(p=0.03, inplace=False)\n",
       "        (19): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (20): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (21): Sigmoid()\n",
       "        (22): Dropout(p=0.03, inplace=False)\n",
       "        (23): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (24): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (25): Sigmoid()\n",
       "        (26): Dropout(p=0.03, inplace=False)\n",
       "        (27): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (28): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (29): Sigmoid()\n",
       "        (30): Dropout(p=0.03, inplace=False)\n",
       "        (31): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (32): Linear(in_features=1088, out_features=128256, bias=True)\n",
       "        (33): Dropout(p=0.03, inplace=False)\n",
       "        (34): LayerNorm((128256,), eps=1e-05, elementwise_affine=True)\n",
       "        (35): Sigmoid()\n",
       "      )\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (1): ResNet(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=7783, out_features=256, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Dropout(p=0.03, inplace=False)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (5): Sigmoid()\n",
       "        (6): Dropout(p=0.03, inplace=False)\n",
       "        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (9): Sigmoid()\n",
       "        (10): Dropout(p=0.03, inplace=False)\n",
       "        (11): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (12): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (13): Sigmoid()\n",
       "        (14): Dropout(p=0.03, inplace=False)\n",
       "        (15): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (16): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (17): Sigmoid()\n",
       "        (18): Dropout(p=0.03, inplace=False)\n",
       "        (19): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (20): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (21): Sigmoid()\n",
       "        (22): Dropout(p=0.03, inplace=False)\n",
       "        (23): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (24): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (25): Sigmoid()\n",
       "        (26): Dropout(p=0.03, inplace=False)\n",
       "        (27): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (28): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (29): Sigmoid()\n",
       "        (30): Dropout(p=0.03, inplace=False)\n",
       "        (31): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (32): Linear(in_features=1088, out_features=128256, bias=True)\n",
       "        (33): Dropout(p=0.03, inplace=False)\n",
       "        (34): LayerNorm((128256,), eps=1e-05, elementwise_affine=True)\n",
       "        (35): Sigmoid()\n",
       "      )\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (2): ResNet(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=7783, out_features=256, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Dropout(p=0.03, inplace=False)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (5): Sigmoid()\n",
       "        (6): Dropout(p=0.03, inplace=False)\n",
       "        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (9): Sigmoid()\n",
       "        (10): Dropout(p=0.03, inplace=False)\n",
       "        (11): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (12): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (13): Sigmoid()\n",
       "        (14): Dropout(p=0.03, inplace=False)\n",
       "        (15): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (16): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (17): Sigmoid()\n",
       "        (18): Dropout(p=0.03, inplace=False)\n",
       "        (19): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (20): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (21): Sigmoid()\n",
       "        (22): Dropout(p=0.03, inplace=False)\n",
       "        (23): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (24): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (25): Sigmoid()\n",
       "        (26): Dropout(p=0.03, inplace=False)\n",
       "        (27): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (28): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (29): Sigmoid()\n",
       "        (30): Dropout(p=0.03, inplace=False)\n",
       "        (31): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (32): Linear(in_features=1088, out_features=128256, bias=True)\n",
       "        (33): Dropout(p=0.03, inplace=False)\n",
       "        (34): LayerNorm((128256,), eps=1e-05, elementwise_affine=True)\n",
       "        (35): Sigmoid()\n",
       "      )\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (3): ResNet(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=7783, out_features=256, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Dropout(p=0.03, inplace=False)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (5): Sigmoid()\n",
       "        (6): Dropout(p=0.03, inplace=False)\n",
       "        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (9): Sigmoid()\n",
       "        (10): Dropout(p=0.03, inplace=False)\n",
       "        (11): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (12): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (13): Sigmoid()\n",
       "        (14): Dropout(p=0.03, inplace=False)\n",
       "        (15): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (16): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (17): Sigmoid()\n",
       "        (18): Dropout(p=0.03, inplace=False)\n",
       "        (19): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (20): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (21): Sigmoid()\n",
       "        (22): Dropout(p=0.03, inplace=False)\n",
       "        (23): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (24): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (25): Sigmoid()\n",
       "        (26): Dropout(p=0.03, inplace=False)\n",
       "        (27): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (28): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (29): Sigmoid()\n",
       "        (30): Dropout(p=0.03, inplace=False)\n",
       "        (31): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (32): Linear(in_features=1088, out_features=128256, bias=True)\n",
       "        (33): Dropout(p=0.03, inplace=False)\n",
       "        (34): LayerNorm((128256,), eps=1e-05, elementwise_affine=True)\n",
       "        (35): Sigmoid()\n",
       "      )\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (4): ResNet(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=7783, out_features=256, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Dropout(p=0.03, inplace=False)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (5): Sigmoid()\n",
       "        (6): Dropout(p=0.03, inplace=False)\n",
       "        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (9): Sigmoid()\n",
       "        (10): Dropout(p=0.03, inplace=False)\n",
       "        (11): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (12): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (13): Sigmoid()\n",
       "        (14): Dropout(p=0.03, inplace=False)\n",
       "        (15): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (16): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (17): Sigmoid()\n",
       "        (18): Dropout(p=0.03, inplace=False)\n",
       "        (19): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (20): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (21): Sigmoid()\n",
       "        (22): Dropout(p=0.03, inplace=False)\n",
       "        (23): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (24): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (25): Sigmoid()\n",
       "        (26): Dropout(p=0.03, inplace=False)\n",
       "        (27): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (28): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (29): Sigmoid()\n",
       "        (30): Dropout(p=0.03, inplace=False)\n",
       "        (31): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (32): Linear(in_features=1088, out_features=128256, bias=True)\n",
       "        (33): Dropout(p=0.03, inplace=False)\n",
       "        (34): LayerNorm((128256,), eps=1e-05, elementwise_affine=True)\n",
       "        (35): Sigmoid()\n",
       "      )\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (5): ResNet(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=7783, out_features=256, bias=True)\n",
       "        (1): Sigmoid()\n",
       "        (2): Dropout(p=0.03, inplace=False)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (5): Sigmoid()\n",
       "        (6): Dropout(p=0.03, inplace=False)\n",
       "        (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (9): Sigmoid()\n",
       "        (10): Dropout(p=0.03, inplace=False)\n",
       "        (11): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (12): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (13): Sigmoid()\n",
       "        (14): Dropout(p=0.03, inplace=False)\n",
       "        (15): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (16): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (17): Sigmoid()\n",
       "        (18): Dropout(p=0.03, inplace=False)\n",
       "        (19): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (20): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (21): Sigmoid()\n",
       "        (22): Dropout(p=0.03, inplace=False)\n",
       "        (23): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (24): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (25): Sigmoid()\n",
       "        (26): Dropout(p=0.03, inplace=False)\n",
       "        (27): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (28): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (29): Sigmoid()\n",
       "        (30): Dropout(p=0.03, inplace=False)\n",
       "        (31): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (32): Linear(in_features=1088, out_features=128256, bias=True)\n",
       "        (33): Dropout(p=0.03, inplace=False)\n",
       "        (34): LayerNorm((128256,), eps=1e-05, elementwise_affine=True)\n",
       "        (35): Sigmoid()\n",
       "      )\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (6): Linear(in_features=4096, out_features=128256, bias=True)\n",
       "  )\n",
       "  (lin_submodel): Linear(in_features=4096, out_features=128256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head, tadapter, optimizer = sequential_models.assemble_model(model, \n",
    "                path2lmhead, \n",
    "                path2tadapter, \n",
    "                start_train=start_train,\n",
    "                to_generate=False,\n",
    "                lm_head_adapter_params=lm_head_adapter_params,\n",
    "                transformer_adapter_params=transformer_adapter_params,\n",
    "                optimizer_params=optimizer_params,\n",
    "                cur_device=device\n",
    "              )\n",
    "if optimizer_params['transformer_update_rate'] == 0.:\n",
    "    tadapter.transformer_float_mode = 16\n",
    "    tadapter.half()\n",
    "    tadapter.eval()\n",
    "head.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f43cee3e-5a7f-4406-a316-3ae81ad030c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cache_mode == 'train_from_cache':\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3c9a9d7-172f-4496-935c-fd9fbc9e7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ЕСЛИ ВДРУГ НАДО ДОБАВИТЬ БОЛЬШЕ СУБМОДЕЛЕЙ\n",
    "# lm_head_adapter_params['composition_size'] = 1\n",
    "# head = sequential_models.extend_head(head, lm_head_adapter_params, transformer_adapter_params, device)\n",
    "\n",
    "# path2tadapter_save = path2tadapter\n",
    "# if optimizer_params['transformer_update_rate'] == 0.:\n",
    "#     path2tadapter_save = None\n",
    "# save_adapters(head, tadapter, path2lmhead, path2tadapter_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "070c93d9-ed7b-4f9f-bcb4-d47b3799475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet depth 36 depth2freeze 0\n"
     ]
    }
   ],
   "source": [
    "#заморозить первые N слоёв выходного резнета\n",
    "print('resnet depth', len(head.submodels[0].layers), 'depth2freeze', depth2freeze)\n",
    "for i in range(len(head.submodels) - 1):\n",
    "    for l_num in range(len(head.submodels[0].layers)):\n",
    "        for p in head.submodels[i].layers[l_num].parameters():\n",
    "            p.requires_grad = l_num < len(head.submodels[0].layers)\n",
    "\n",
    "# for l_num in range(len(head.submodels[0].layers)):\n",
    "#     for p in head.submodels[0].layers[l_num].parameters():\n",
    "#         print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e2990d7-4218-4aaf-b948-ae750a8cb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#head.submodels[0].layers[-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cf32a5c-8f32-4124-a2e3-cd9943d3a841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=7783, out_features=256, bias=True)\n",
       "  (1): Sigmoid()\n",
       "  (2): Dropout(p=0.03, inplace=False)\n",
       "  (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (5): Sigmoid()\n",
       "  (6): Dropout(p=0.03, inplace=False)\n",
       "  (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (9): Sigmoid()\n",
       "  (10): Dropout(p=0.03, inplace=False)\n",
       "  (11): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (12): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (13): Sigmoid()\n",
       "  (14): Dropout(p=0.03, inplace=False)\n",
       "  (15): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (16): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (17): Sigmoid()\n",
       "  (18): Dropout(p=0.03, inplace=False)\n",
       "  (19): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (20): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (21): Sigmoid()\n",
       "  (22): Dropout(p=0.03, inplace=False)\n",
       "  (23): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (24): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (25): Sigmoid()\n",
       "  (26): Dropout(p=0.03, inplace=False)\n",
       "  (27): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (28): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (29): Sigmoid()\n",
       "  (30): Dropout(p=0.03, inplace=False)\n",
       "  (31): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (32): Linear(in_features=1088, out_features=128256, bias=True)\n",
       "  (33): Dropout(p=0.03, inplace=False)\n",
       "  (34): LayerNorm((128256,), eps=1e-05, elementwise_affine=True)\n",
       "  (35): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.submodels[0].layers#[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9977600-efbf-435d-a573-69ed74961c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_drop_idx = 0.03\n",
    "lambda_l2 = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41b39554-479c-41a8-8dcf-1b7456c753e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#снять метрики\n",
    "if cache_mode != 'train_from_cache':\n",
    "    if not start_train:\n",
    "        sequential_models.assemble_model(model, \n",
    "            path2lmhead, \n",
    "            path2tadapter, \n",
    "            start_train=False,\n",
    "            to_generate=True,\n",
    "            lm_head_adapter_params=lm_head_adapter_params,\n",
    "            transformer_adapter_params=transformer_adapter_params,\n",
    "            optimizer_params=optimizer_params,\n",
    "            cur_device=device\n",
    "          )\n",
    "        current_benchmark = LLMBenchmark()\n",
    "        results = current_benchmark.run(model, tokenizer, device)\n",
    "        sequential_models.disassemble_model(model)\n",
    "        print(results)\n",
    "    #{'fact_score': 0.109, 'translation_rouge': 0.33223}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46c99a49-fa06-42f4-9f11-4527bb296bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-09 09:23:19.825115\n"
     ]
    }
   ],
   "source": [
    "print(pd.Timestamp.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fbd4b77-5877-4f01-8df2-42bdff82287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing cache loader from D:\\cache\\cache_instruct\n",
      "Found 68 cache files with ~13600000 samples\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "class CacheLoader:\n",
    "    def __init__(self, cache_dir, shuffle=True, batch_size=1024):\n",
    "        \"\"\"Инициализация загрузчика кэша с ленивой загрузкой файлов батчами.\"\"\"\n",
    "        self.cache_files = glob.glob(os.path.join(cache_dir, \"*.pkl\"))\n",
    "        if shuffle:\n",
    "            random.shuffle(self.cache_files)\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.file_ptr = 0  # Указатель на текущий файл в списке cache_files\n",
    "        self.current_data = None  # Данные текущего загруженного файла\n",
    "        self.batch_ptr = 0  # Указатель на текущую позицию батча в current_data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Примерное количество семплов во всех файлах\"\"\"\n",
    "        # Можно сделать точнее, но для наших целей достаточно\n",
    "        return len(self.cache_files) * SAMPLE_PER_FILE  # Примерно по 10000 семплов в файле\n",
    "\n",
    "    def _count_samples(self, file_path):\n",
    "        \"\"\"Подсчитывает количество сэмплов в файле.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                return data['states'].shape[0]\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    def _load_next_file(self):\n",
    "        \"\"\"Загружает следующий подходящий файл, пропуская слишком маленькие.\"\"\"\n",
    "        while True:\n",
    "            # Проверяем, нужно ли перейти к началу списка файлов\n",
    "            if self.file_ptr >= len(self.cache_files):\n",
    "                self.file_ptr = 0\n",
    "                if self.shuffle:\n",
    "                    random.shuffle(self.cache_files)\n",
    "\n",
    "            file_path = self.cache_files[self.file_ptr]\n",
    "            self.batch_ptr = 0\n",
    "            try:\n",
    "            #if 1:\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                    num_samples = data['states'].shape[0]\n",
    "                    print('loaded', file_path)\n",
    "\n",
    "                    # Пропускаем файлы с недостаточным количеством сэмплов\n",
    "                    if num_samples < self.batch_size:\n",
    "                        print(f\"Skipping {file_path} (samples: {num_samples} < {self.batch_size})\")\n",
    "                        self.file_ptr += 1\n",
    "                        continue\n",
    "\n",
    "                    # Перемешиваем данные внутри файла\n",
    "                    if self.shuffle:\n",
    "                        perm = torch.randperm(num_samples)\n",
    "                        for key in ['states', 'labels', 'weights']:\n",
    "                            data[key] = data[key][perm]\n",
    "\n",
    "                    self.current_data = data\n",
    "                    self.file_ptr += 1  # Переходим к следующему файлу для следующей загрузки\n",
    "                    break  # Успешно загрузили файл\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {str(e)}\")\n",
    "                #self.file_ptr += 1\n",
    "                os.remove(file_path)\n",
    "                del self.cache_files[self.file_ptr]\n",
    "\n",
    "    def get_sample(self):\n",
    "        \"\"\"Возвращает следующий батч данных из кэша.\"\"\"\n",
    "        while True:\n",
    "            # Если данные не загружены или текущий батч исчерпан, загружаем следующий файл\n",
    "            if self.current_data is None or (self.batch_ptr + self.batch_size) > self.current_data['states'].shape[0]:\n",
    "                self._load_next_file()\n",
    "\n",
    "            # Извлекаем батч из текущих данных\n",
    "            start = self.batch_ptr\n",
    "            end = start + self.batch_size\n",
    "            batch = {\n",
    "                'states': self.current_data['states'][start:end],\n",
    "                'labels': self.current_data['labels'][start:end],\n",
    "                'weights': self.current_data['weights'][start:end]\n",
    "            }\n",
    "            self.batch_ptr += self.batch_size\n",
    "            return batch\n",
    "\n",
    "def save_cache_block(cache_buffer, cache_dir):\n",
    "    try:\n",
    "        cache_buffer['states'] = torch.vstack(cache_buffer['states'])\n",
    "        cache_buffer['labels'] = torch.cat(cache_buffer['labels'])\n",
    "        cache_buffer['weights'] = torch.cat(cache_buffer['weights'])\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    filename = f\"cache{pd.Timestamp.now()}.pkl\".replace(' ', \"_\").replace(':', \"_\")\n",
    "    with open(f\"{cache_dir}\\\\{filename}\", 'wb') as f:\n",
    "        pickle.dump(cache_buffer, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Инициализация кэш-лоадера\n",
    "if use_cache:\n",
    "    print(f\"Initializing cache loader from {cache_dir}\")\n",
    "    cache_loader = CacheLoader(cache_dir)\n",
    "    print(f\"Found {len(cache_loader.cache_files)} cache files with ~{len(cache_loader)} samples\")\n",
    "\n",
    "if generate_cache:\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    cache_buffer = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e586d9dd-8124-4868-b5ea-d0c6238a85d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 1\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-06-06_18_51_55.623226.pkl\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-30_11_29_01.874975.pkl\n",
      "ce_loss 3.339 300 from 1000000 0.03 % acc 0.5077213541666666 2025-06-09 09:25:14.977759\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-06-05_17_11_32.519994.pkl\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-27 13_37_03.251182.pkl\n",
      "ce_loss 3.174 600 from 1000000 0.06 % acc 0.5230078125 2025-06-09 09:39:17.342266\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-30_10_55_26.942805.pkl\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-27_17_58_09.989139.pkl\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-27_16_24_52.114339.pkl\n",
      "ce_loss 3.132 900 from 1000000 0.09 % acc 0.5385677083333333 2025-06-09 09:51:59.261246\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-30_08_11_11.908148.pkl\n",
      "ce_loss 3.293 1200 from 1000000 0.12 % acc 0.5256640625 2025-06-09 10:02:46.350651\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-30_14_07_02.458290.pkl\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-30_12_05_18.960047.pkl\n",
      "ce_loss 3.155 1500 from 1000000 0.15 % acc 0.5367643229166666 2025-06-09 10:15:52.629480\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-30_13_49_56.374839.pkl\n",
      "ce_loss 3.105 1800 from 1000000 0.18 % acc 0.5407291666666667 2025-06-09 10:42:43.732052\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-27_15_32_47.475570.pkl\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-05-27 13_12_14.099780.pkl\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-06-05_18_21_08.853152.pkl\n",
      "loaded D:\\cache\\cache_instruct\\cache2025-06-05_17_39_16.186870.pkl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 181\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m train_anything:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m acc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((torch\u001b[38;5;241m.\u001b[39margmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[43mlabels_cur\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_start_pointer\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_start_pointer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_batch_size4loss\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat16))\n\u001b[0;32m    182\u001b[0m acc_copy \u001b[38;5;241m=\u001b[39m acc\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m logits\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TRAIN!!!\n",
    "#Если вы задаётесь вопросом, почему такой странный цикл обучения, давайте посмотрим, что не сработало в \"нормальных\" циклах обучения.\n",
    "#Можно было запихнуть трансформерный адаптер и lm-resnet в исходную LLM, разморозить их и заморозить всё остальное. \n",
    "#НО тогда по непонятной причине выходила крайне плохая точность обучения. loss = 1.65 на датасете, где у классического TEA (ну, чисто резнеты) loss = 0.85\n",
    "#Две недели поисков выявили, что видимое различие в том, что в одном случае адаптер обучает ВНУТРИ сетки, а в другом СНАРУЖИ. Снаружи ПОЧЕМУ-ТО лучше\n",
    "#\n",
    "#Если проинференсить трансформерный адаптер, а потом LM-head, то запросто может получиться, что на этапе backward мы сдохнем по памяти.\n",
    "#Как фиксить? Делаем, чтобы для всего множества эмбеддингов от трансформерной части loss считался батчами\n",
    "#В таком случае возникает ошибка, мол, чё нам делать с градиентами в трансформерном адаптере - мы же их уже посчитали, а ты предлагаешь считать ещё раз!\n",
    "#Решаем так: берёт сабсемпл от эмбеддингов трансформерного адаптера и считаем loss на сабсемпле\n",
    "#Это не вполне честно, так как мы менее тщательно учитываем длинные последовательности, но эй, это работает!\n",
    "\n",
    "print('batch_size', optimizer_params['batch_size'])\n",
    "i_pointer = 0\n",
    "\n",
    "batch_accum_counter = 0\n",
    "loss_array = []\n",
    "metr_array = []\n",
    "\n",
    "log = []\n",
    "while 1: \n",
    "    i = 0\n",
    "    if not use_cache:\n",
    "        input_ids_full = []\n",
    "        labels_full = []\n",
    "        weights_full = []\n",
    "        while i < optimizer_params['batch_size']:\n",
    "            if not use_cache:\n",
    "                sample_cur  = dataset[i_pointer + i]\n",
    "                input_ids = sample_cur['input_ids']\n",
    "                labels = sample_cur['labels']\n",
    "                weights = sample_cur['mult']\n",
    "                \n",
    "                input_ids_len = len(input_ids)\n",
    "                labels_len = len(labels)\n",
    "                input_ids = input_ids[input_ids!=padding_token]\n",
    "                \n",
    "                drop_idx = torch.rand_like(input_ids.to(torch.float)) < proba_drop_idx\n",
    "                input_ids = input_ids[~drop_idx]\n",
    "                \n",
    "                labels = labels[labels!=padding_token]\n",
    "                padding_size = input_ids_len + labels_len - len(input_ids) - len(labels)\n",
    "                input_ids_cur = torch.cat([input_ids, labels, torch.zeros(padding_size, dtype=torch.int32) + padding_token])[:max_seq_len4inference]\n",
    "                #print('input_ids', input_ids.shape, 'labels', labels.shape)\n",
    "                labels_cur = torch.cat([input_ids * 0 + padding_token, labels, torch.zeros(padding_size, dtype=torch.int32) + padding_token])[:max_seq_len4inference]\n",
    "                if torch.all(labels_cur) == padding_token:\n",
    "                    print('empty label')\n",
    "                    continue\n",
    "                \n",
    "                input_ids_full.append(input_ids_cur[:-1])\n",
    "                labels_full.append(labels_cur[1:])\n",
    "                weights_full.append(weights)\n",
    "                #log += [labels_cur.shape[0], input_ids_cur.shape[0]]\n",
    "            i += 1\n",
    "            \n",
    "        i_pointer += i #should be batch_size\n",
    "        with torch.no_grad():\n",
    "            input_ids_full = torch.stack(input_ids_full).to(device)\n",
    "            labels_full = torch.stack(labels_full).to(device)\n",
    "            weights_full = torch.stack(weights_full).to(device).T\n",
    "    \n",
    "            cnt_pads = count_padding(labels_full, padding_token)\n",
    "            if cnt_pads >= input_ids_full.shape[1] - 5:\n",
    "                continue\n",
    "            if cnt_pads > 0:\n",
    "                input_ids_full = input_ids_full[:, :-cnt_pads]\n",
    "                labels_full = labels_full[:, :-cnt_pads]\n",
    "                \n",
    "            outp = model.forward(input_ids_full, output_hidden_states=True, return_dict=True)\n",
    "            #outp = model.forward(input_ids_full, output_hidden_states=False, return_dict=True)\n",
    "            state_full = outp['hidden_states'][-1][:, :input_ids_full.shape[1]].detach()\n",
    "    \n",
    "            weights_full2d = torch.vstack([weights_full] * labels_full.shape[-1]).to(device).T\n",
    "            labels_cur = labels_full.ravel()#.cpu().numpy()\n",
    "            \n",
    "            weights_cur = weights_full2d.ravel()\n",
    "    \n",
    "            del labels_full\n",
    "            del weights_full2d\n",
    "            del weights_full\n",
    "            del outp\n",
    "            idx = torch.isin(labels_cur, torch.tensor(forbidden_tokens_list).to(device))\n",
    "            labels_cur = labels_cur[~idx]\n",
    "            weights_cur = weights_cur[~idx]\n",
    "    \n",
    "        \n",
    "        if state_full.shape[0] == 0:\n",
    "            continue\n",
    "    \n",
    "        #Для скорости считаем градиенты через трансформер не всегда\n",
    "        req_current = np.random.rand() < optimizer_params['transformer_update_rate']\n",
    "        for p in tadapter.parameters():\n",
    "            p.requires_grad = req_current\n",
    "    \n",
    "        state_full = tadapter(state_full)[0]\n",
    "        state_cur = state_full.reshape([state_full.shape[0] * state_full.shape[1], state_full.shape[2]])\n",
    "        state_cur = state_cur[~idx]\n",
    "        if state_cur.shape[0] > max_loss_len:\n",
    "            state_cur = state_cur[:max_loss_len]\n",
    "    \n",
    "        #ограничить размер\n",
    "        \n",
    "        #print('state_cur', state_cur.shape)\n",
    "        del state_full\n",
    "        perm = torch.randperm(state_cur.size(0), device=device)\n",
    "        state_cur = state_cur[perm]\n",
    "        weights_cur = weights_cur[perm]\n",
    "        labels_cur = labels_cur[perm]\n",
    "    \n",
    "    loss = None\n",
    "\n",
    "    if use_cache:\n",
    "        # Режим использования кэша\n",
    "        sample = cache_loader.get_sample()\n",
    "        # Извлекаем предвычисленные данные\n",
    "        state_cur = sample['states']#.to(device)\n",
    "        labels_cur = sample['labels']#.to(device)\n",
    "        weights_cur = sample['weights']#.to(device)\n",
    "        i_pointer += state_cur.shape[0]//1000\n",
    "\n",
    "    \n",
    "    for x_start_pointer in range(0, state_cur.shape[0], max_batch_size4loss):\n",
    "        #logits = head(state_cur.to(torch.float32)[x_start_pointer: x_start_pointer + max_batch_size4loss])\n",
    "        # Сохранение в кэш при необходимости\n",
    "        if generate_cache:\n",
    "            if 'states' in cache_buffer:\n",
    "                cache_buffer['states'] += [state_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].cpu().half()]#torch.vstack([cache_buffer['states'], state_cur.cpu().half()])\n",
    "                cache_buffer['labels'] += [labels_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].view(-1).cpu()]#torch.cat([cache_buffer['labels'], labels_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].view(-1).cpu()])\n",
    "                cache_buffer['weights'] += [weights_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].cpu()]#torch.cat([cache_buffer['weights'], weights_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].cpu()])\n",
    "                cache_buffer['len'] += cache_buffer['states'][-1].shape[0]\n",
    "            else:\n",
    "                cache_buffer['states'] = [state_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].cpu().half()]\n",
    "                cache_buffer['labels'] = [labels_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].view(-1).cpu()]\n",
    "                cache_buffer['weights'] = [weights_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].cpu()]\n",
    "                cache_buffer['len'] = state_cur.shape[0]\n",
    "\n",
    "            if cache_buffer['len'] >= SAMPLE_PER_FILE:\n",
    "                print('saving cache', i_pointer, pd.Timestamp.now())\n",
    "                save_cache_block(cache_buffer, cache_dir)\n",
    "                cache_buffer = {}\n",
    "        \n",
    "        if train_anything:\n",
    "            if use_cp_for_head:\n",
    "                logits = torch.utils.checkpoint.checkpoint(head, state_cur.to(torch.float32)[x_start_pointer: x_start_pointer + max_batch_size4loss].to(device))\n",
    "            else:\n",
    "                logits = head(state_cur.to(torch.float32)[x_start_pointer: x_start_pointer + max_batch_size4loss].to(device))\n",
    "                \n",
    "            ce_loss = loss_fct(logits, labels_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].view(-1).to(device))\n",
    "            ce_loss = ce_loss * weights_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].to(device)\n",
    "            ce_loss = torch.clamp(ce_loss, -0.9, 10.0)#soft_clip(ce_loss, -0.6, 10.)\n",
    "            loss = torch.mean(ce_loss)\n",
    "\n",
    "            #l2 регуляризация\n",
    "            l2_reg = torch.tensor(0.0, device=device)\n",
    "            for param in tadapter.parameters():\n",
    "                if param.requires_grad:\n",
    "                    l2_reg += torch.norm(param)\n",
    "            for param in head.parameters():\n",
    "                if param.requires_grad:\n",
    "                    l2_reg += torch.norm(param)\n",
    "            #l2_reg = sum(p.norm(2) ** 2 for p in chain(tadapter.parameters(), head.parameters()) / 1e6)\n",
    "                         \n",
    "            total_loss = loss + lambda_l2 * l2_reg\n",
    "            \n",
    "            total_loss.backward()\n",
    "         \n",
    "            # Клиппинг градиентов: обрезает норму градиентов до 2.0\n",
    "            torch.nn.utils.clip_grad_norm_(tadapter.parameters(), max_norm=1.0) #* optimizer_params['accum_batch'])\n",
    "            torch.nn.utils.clip_grad_norm_(head.parameters(), max_norm=1.0) #* optimizer_params['accum_batch'])\n",
    "            \n",
    "            # if state_cur.shape[0] - (x_start_pointer + max_batch_size4loss) > 0:\n",
    "            #     print('cannot backward, shape', state_cur.shape[0] - (x_start_pointer + max_batch_size4loss))\n",
    "            break\n",
    "       \n",
    "    del state_cur\n",
    "    del weights_cur\n",
    "    \n",
    "\n",
    "    if not train_anything:\n",
    "        continue\n",
    "    acc = torch.mean((torch.argmax(logits, axis=-1) == labels_cur[x_start_pointer: x_start_pointer + max_batch_size4loss].to(device)).to(torch.float16))\n",
    "    acc_copy = acc.cpu().numpy()\n",
    "    del logits\n",
    "    del labels_cur\n",
    "    batch_accum_counter += 1\n",
    "    loss_array += [torch.mean(ce_loss).item()]\n",
    "    metr_array += [acc.item()]\n",
    "    if batch_accum_counter >= optimizer_params['accum_batch'] :\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        torch.cuda.empty_cache()\n",
    "        if not train_anything:\n",
    "            data_len = len(dataset)\n",
    "        else:\n",
    "            data_len = 1000000\n",
    "        print('ce_loss', np.round(np.mean(loss_array), 3), i_pointer, 'from', data_len, np.round(100 * i_pointer/data_len, 5), '%', 'acc', np.mean(metr_array), pd.Timestamp.now())\n",
    "        \n",
    "        loss_array = []\n",
    "        metr_array = []\n",
    "        batch_accum_counter = 0\n",
    "        if (np.random.rand() < 1 and optimizer_params['accum_batch'] > 500) or (np.random.rand() < 0.1 and optimizer_params['accum_batch']  <= 500):\n",
    "            try:\n",
    "                path2tadapter_save = path2tadapter\n",
    "                if optimizer_params['transformer_update_rate'] == 0.:\n",
    "                    path2tadapter_save = None\n",
    "                save_adapters(head, tadapter, path2lmhead, path2tadapter_save)\n",
    "                if np.random.rand()<0.1:\n",
    "                    path2tadapter_save = path2tadapter\n",
    "                if optimizer_params['transformer_update_rate'] == 0.:\n",
    "                    path2tadapter_save = None\n",
    "                else:\n",
    "                    path2tadapter_save =  path2tadapter + '.back'\n",
    "                save_adapters(head, tadapter, path2lmhead, path2tadapter_save)\n",
    "\n",
    "            except Exception:\n",
    "                #Я не хочу, чтобы скрипт падал только потому, что кто-то завалил веь диск\n",
    "                print(\"not saved\")\n",
    "            #снять метрики\n",
    "            if not use_cache:\n",
    "                sequential_models.assemble_model(model, \n",
    "                    path2lmhead, \n",
    "                    path2tadapter, \n",
    "                    start_train=False,\n",
    "                    to_generate=True,\n",
    "                    lm_head_adapter_params=lm_head_adapter_params,\n",
    "                    transformer_adapter_params=transformer_adapter_params,\n",
    "                    optimizer_params=optimizer_params,\n",
    "                    cur_device=device\n",
    "                  )\n",
    "                current_benchmark = LLMBenchmark()\n",
    "                results = current_benchmark.run(model, tokenizer, device,4)\n",
    "                sequential_models.disassemble_model(model)\n",
    "                print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602912b-4171-4b9d-8b0a-d4af1b5f1bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cache_block(cache_buffer, cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a50ab91-00e3-427a-9458-8cc74273a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_accum_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ad884-d47e-4d8a-82c3-60f4e2b120d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#33 min за 1300 при batch_size=1\n",
    "#45 min за 1300 при batch_size=2\n",
    "#21 min за 1300 при batch_size=1, 'transformer_update_rate' = 0.1\n",
    "#24 min за 1300 при batch_size=1, 'transformer_update_rate' = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1541c-8079-4c2d-abc6-815fedd44fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Проверка градиентов после backward()\n",
    "print(\"\\nГрадиенты после backward:\")\n",
    "for name, param in chain(head.named_parameters(), tadapter.named_parameters()):\n",
    "    if param.grad is not None:\n",
    "        print(f\"{name}: mean_grad = {param.grad.abs().mean().item()}\")\n",
    "    else:\n",
    "        print(f\"{name}: Нет градиента\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bb0d448-2a4d-4153-adbf-5bdfc27b6831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n",
      "ce_loss 3.314 2067 % acc 0.516351914943609 2025-06-09 10:55:00.685029\n"
     ]
    }
   ],
   "source": [
    "#если принудительно стопнули, можно добить батч\n",
    "# Сохраняем веса перед обновлением\n",
    "#before_step_head = [p.data.clone() for p in head.parameters()]\n",
    "#before_step_tadapter = [p.data.clone() for p in tadapter.parameters()]\n",
    "\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "torch.cuda.empty_cache()\n",
    "print(batch_accum_counter)\n",
    "print('ce_loss', np.round(np.mean(loss_array), 3), i_pointer, '%', 'acc', np.mean(metr_array), pd.Timestamp.now())\n",
    "\n",
    "# # Проверяем изменения весов\n",
    "# for i, (p_before, p_after) in enumerate(zip(before_step_head, head.parameters())):\n",
    "#     change = torch.abs(p_before - p_after.data).mean().item()\n",
    "#     print(f\"Head layer {i}: weight change = {change}\")\n",
    "\n",
    "# for i, (p_before, p_after) in enumerate(zip(before_step_tadapter, tadapter.parameters())):\n",
    "#     change = torch.abs(p_before - p_after.data).mean().item()\n",
    "#     print(f\"Tadapter layer {i}: weight change = {change}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36bc3705-a864-4c7f-bf5e-5cc592eae6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ручной сейв\n",
    "path2tadapter_save = path2tadapter\n",
    "if optimizer_params['transformer_update_rate'] == 0.:\n",
    "    path2tadapter_save = None\n",
    "save_adapters(head, tadapter, path2lmhead, path2tadapter_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19e26e-4153-486c-912b-b8bab08f4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#тестим модель\n",
    "sequential_models.assemble_model(model, \n",
    "                path2lmhead, \n",
    "                path2tadapter, \n",
    "                start_train=False,\n",
    "                to_generate=True,\n",
    "                lm_head_adapter_params=lm_head_adapter_params,\n",
    "                transformer_adapter_params=transformer_adapter_params,\n",
    "                optimizer_params=optimizer_params,\n",
    "                cur_device=device\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256ef640-f536-4479-92a1-1f285fdebe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = 'Твоя роль: Сталин. \\n Серёга: Какая фракция в игре Герои Меча и Магии 3 соответствует твоей личности? Your answer, ONLY ENGLISH (end by \"|\"):'\n",
    "# prompt = ''''Шэдоухарт девушка сорока восьми лет. У неё черные волосы, заплетенные в длинную косу, и зеленые глаза, а справа на лице присутствует длинный шрам. Облачена в среднюю броню, вооружена булавой и круглым деревянным щитом. На голове девушка носит металлический обруч.\n",
    "\n",
    "# Психологический профиль\n",
    "# Шэдоухарт осторожна и не склонна раскрывать информацию о себе, своих мотивах и реликвии, которую она носит. С особым недоверием она'''\n",
    "#prompt = 'Твоя роль: Девушка-флористка. \\n Серёга: Какая фракция в игре Герои Меча и Магии 3 соответствует твоей личности? Your answer, ONLY ENGLISH (end by \"|\"):'\n",
    "#prompt = 'Твоя роль: Data scientist. \\n Серёга: Мне надо улучшить LLM. У меня ресурсы на запуск Llama 3.1 8B или Qwen 2.5 14B, квантованные до 4 бит. Мне нужно, чтобы мои модели былу умнее (на уровне 70 B), но при этом имели настолько же низкие требования по памяти и запускались так же быстро. Я готов обучать новую модель. Я готов пробовать другие архитектуры. Опиши план, что делать. Your answer, ONLY ENGLISH  (end by \"|\"):'\n",
    "#prompt = 'Твоя роль: Инженер-ракетчик. \\n Серёга: Мне надо сделать ракету, в домашних условиях, небольшую. Расскажи, как это провернуть? ТВОЙ ОТВЕТ НА РУССКОМ  (end by \"|\"):'\n",
    "#prompt = 'Твоя роль: Геймер, студент-инженер. \\n Серёга: Перечисли всех монстров из Doom, каких вспомнишь! Your answer, ONLY ENGLISH  (end by \"|\"):'\n",
    "#prompt = 'Твоя роль: Гермиона Грейнджер. \\n Серёга: Как справиться с василиском? Your answer, НА РУССКОМ (end by \"|\", 200 tokens):'\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "repetition_penalty = 1.2\n",
    "t = pd.Timestamp.now()\n",
    "generate_ids = model.generate(inputs.input_ids.to(device),\n",
    "                                        #attention_mask=inputs[\"attention_mask\"],\n",
    "                                        top_k=200,\n",
    "                                        top_p=0.9,\n",
    "                                        max_new_tokens=200,\n",
    "                                        temperature=0.01,\n",
    "                                        pad_token_id=tokenizer.pad_token_id,\n",
    "                                        eos_token_id=tokenizer.eos_token_id,\n",
    "                                        bos_token_id=tokenizer.bos_token_id,\n",
    "                                        #no_repeat_ngram_size=3,\n",
    "                                        repetition_penalty=repetition_penalty,\n",
    "                                        early_stopping=True,\n",
    "                                        use_cache=True,\n",
    "                                        num_beams=1,\n",
    "                                        tokenizer=tokenizer)\n",
    "print(pd.Timestamp.now() - t)\n",
    "answer = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b56d4-fcaf-4bb3-b156-8c2627b4b773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b484f-c956-4e3e-b372-636eb3f64061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085bfd20-f864-4986-9426-4f10dda8be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
