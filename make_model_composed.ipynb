{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f211d5f3-5f53-4380-9241-7e471ba073ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#учит LLM в сборе. То есть приделываем в конец feature head и так и учим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5889c1ea-bfb9-4a28-adfd-200fc1251ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "install = False\n",
    "if install:\n",
    "    !conda install -c anaconda git -y\n",
    "\n",
    "    !pip install deepspeed==0.14.4\n",
    "\n",
    "    !pip install --upgrade pip\n",
    "    !pip install --upgrade transformers==4.46.2 tyro==0.9.8 triton==2.3.1 trl==0.12.0\n",
    "\n",
    "    !pip install -v \"xformers==0.0.29.post1\"\n",
    "    !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "    !pip install --no-deps -v \"peft==0.13.2\"\n",
    "    !pip install --no-deps packaging ninja einops flash-attn bitsandbytes==0.44.1\n",
    "    !pip install accelerate==0.34.2\n",
    "    #!curl -fsSL https://ollama.com/install.sh | sh\n",
    "    !pip uninstall peft -y\n",
    "    !pip install -v \"peft==0.13.2\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "304f9000-7a9e-4ccf-9540-44107787160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/home/ssdovgan/main/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mabsl-py==2.2.2\n",
      "accelerate==0.34.2\n",
      "aiohappyeyeballs==2.6.1\n",
      "aiohttp==3.11.14\n",
      "aiosignal==1.3.2\n",
      "annotated-types==0.7.0\n",
      "anyio==4.9.0\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==3.0.0\n",
      "async-lru==2.0.5\n",
      "attrs==25.3.0\n",
      "babel==2.17.0\n",
      "beautifulsoup4==4.13.3\n",
      "bitsandbytes==0.44.1\n",
      "bleach==6.2.0\n",
      "certifi==2025.1.31\n",
      "cffi==1.17.1\n",
      "charset-normalizer==3.4.1\n",
      "click==8.1.8\n",
      "comm==0.2.2\n",
      "cut-cross-entropy==25.1.1\n",
      "dataclasses-json==0.6.7\n",
      "datasets==3.4.1\n",
      "debugpy==1.8.13\n",
      "decorator==5.2.1\n",
      "deepspeed==0.14.4\n",
      "defusedxml==0.7.1\n",
      "dill==0.3.8\n",
      "docstring_parser==0.16\n",
      "einops==0.8.1\n",
      "executing==2.2.0\n",
      "fastjsonschema==2.21.1\n",
      "filelock==3.18.0\n",
      "flash_attn==2.7.4.post1\n",
      "fqdn==1.5.1\n",
      "frozenlist==1.5.0\n",
      "fsspec==2024.12.0\n",
      "gigachat==0.1.39.post2\n",
      "GPUtil==1.4.0\n",
      "greenlet==3.2.3\n",
      "h11==0.14.0\n",
      "hf_transfer==0.1.9\n",
      "hjson==3.1.0\n",
      "httpcore==1.0.7\n",
      "httpx==0.28.1\n",
      "httpx-sse==0.4.1\n",
      "huggingface-hub==0.29.3\n",
      "idna==3.10\n",
      "ipykernel==6.29.5\n",
      "ipython==9.0.2\n",
      "ipython_pygments_lexers==1.1.1\n",
      "ipywidgets==8.1.5\n",
      "isoduration==20.11.0\n",
      "jedi==0.19.2\n",
      "Jinja2==3.1.6\n",
      "joblib==1.4.2\n",
      "json5==0.10.0\n",
      "jsonpatch==1.33\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2024.10.1\n",
      "jupyter==1.1.1\n",
      "jupyter-console==6.6.3\n",
      "jupyter-events==0.12.0\n",
      "jupyter-lsp==2.2.5\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "jupyter_server==2.15.0\n",
      "jupyter_server_terminals==0.5.3\n",
      "jupyterlab==4.3.6\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.27.3\n",
      "jupyterlab_widgets==3.0.13\n",
      "langchain==0.3.26\n",
      "langchain-community==0.3.26\n",
      "langchain-core==0.3.66\n",
      "langchain-text-splitters==0.3.8\n",
      "langsmith==0.4.1\n",
      "lxml==5.4.0\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==3.0.2\n",
      "marshmallow==3.26.1\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "mistune==3.1.3\n",
      "mpmath==1.3.0\n",
      "multidict==6.2.0\n",
      "multiprocess==0.70.16\n",
      "mypy_extensions==1.1.0\n",
      "nbclient==0.10.2\n",
      "nbconvert==7.16.6\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.4.2\n",
      "ninja==1.11.1.4\n",
      "nltk==3.9.1\n",
      "notebook==7.3.3\n",
      "notebook_shim==0.2.4\n",
      "numpy==2.2.4\n",
      "nvidia-cublas-cu12==12.4.5.8\n",
      "nvidia-cuda-cupti-cu12==12.4.127\n",
      "nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "nvidia-cuda-runtime-cu12==12.4.127\n",
      "nvidia-cudnn-cu12==9.1.0.70\n",
      "nvidia-cufft-cu12==11.2.1.3\n",
      "nvidia-curand-cu12==10.3.5.147\n",
      "nvidia-cusolver-cu12==11.6.1.9\n",
      "nvidia-cusparse-cu12==12.3.1.170\n",
      "nvidia-cusparselt-cu12==0.6.2\n",
      "nvidia-ml-py==12.570.86\n",
      "nvidia-nccl-cu12==2.21.5\n",
      "nvidia-nvjitlink-cu12==12.4.127\n",
      "nvidia-nvtx-cu12==12.4.127\n",
      "orjson==3.10.18\n",
      "overrides==7.7.0\n",
      "packaging==24.2\n",
      "pandas==2.2.3\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.4\n",
      "peft==0.13.2\n",
      "pexpect==4.9.0\n",
      "pillow==11.1.0\n",
      "platformdirs==4.3.7\n",
      "prometheus_client==0.21.1\n",
      "prompt_toolkit==3.0.50\n",
      "propcache==0.3.1\n",
      "protobuf==3.20.3\n",
      "psutil==7.0.0\n",
      "ptyprocess==0.7.0\n",
      "pure_eval==0.2.3\n",
      "py-cpuinfo==9.0.0\n",
      "pyarrow==19.0.1\n",
      "pycparser==2.22\n",
      "pydantic==2.10.6\n",
      "pydantic-settings==2.10.1\n",
      "pydantic_core==2.27.2\n",
      "Pygments==2.19.1\n",
      "python-dateutil==2.9.0.post0\n",
      "python-docx==1.2.0\n",
      "python-dotenv==1.1.1\n",
      "python-json-logger==3.3.0\n",
      "pytz==2025.2\n",
      "PyYAML==6.0.2\n",
      "pyzmq==26.3.0\n",
      "referencing==0.36.2\n",
      "regex==2024.11.6\n",
      "requests==2.32.3\n",
      "requests-toolbelt==1.0.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rich==13.9.4\n",
      "rouge==1.0.1\n",
      "rouge_score==0.1.2\n",
      "rpds-py==0.24.0\n",
      "safetensors==0.5.3\n",
      "Send2Trash==1.8.3\n",
      "sentencepiece==0.2.0\n",
      "setuptools==78.1.0\n",
      "shtab==1.7.1\n",
      "six==1.17.0\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.6\n",
      "SQLAlchemy==2.0.41\n",
      "stack-data==0.6.3\n",
      "sympy==1.13.1\n",
      "tenacity==9.1.2\n",
      "terminado==0.18.1\n",
      "tinycss2==1.4.0\n",
      "tokenizers==0.20.3\n",
      "torch==2.5.1\n",
      "tornado==6.4.2\n",
      "tqdm==4.67.1\n",
      "traitlets==5.14.3\n",
      "transformers==4.46.2\n",
      "triton==3.1.0\n",
      "trl==0.12.0\n",
      "typeguard==4.4.2\n",
      "types-python-dateutil==2.9.0.20241206\n",
      "typing-inspect==0.9.0\n",
      "typing-inspection==0.4.1\n",
      "typing_extensions==4.13.0\n",
      "tyro==0.9.8\n",
      "tzdata==2025.2\n",
      "unsloth @ git+https://github.com/unslothai/unsloth.git@2ff5dc1a8de1614994a275785b7b64fb4db8cb5d\n",
      "unsloth_zoo==2025.3.17\n",
      "uri-template==1.3.0\n",
      "urllib3==2.3.0\n",
      "wcwidth==0.2.13\n",
      "webcolors==24.11.1\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "wheel==0.45.1\n",
      "widgetsnbextension==4.0.13\n",
      "wldhx.yadisk-direct==0.0.6\n",
      "xformers==0.0.29.post1\n",
      "xxhash==3.5.0\n",
      "yarl==1.18.3\n",
      "zstandard==0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2570a2e2-a09e-44ad-a77b-c4b8357581ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import os, pickle, random\n",
    "import psutil\n",
    "import warnings\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from typing import Dict, List, Optional\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "from torch import cuda, LongTensor, FloatTensor\n",
    "from peft import PeftModel, PeftConfig, PeftModelForCausalLM\n",
    "\n",
    "import ensembles\n",
    "from data_tools import InstructDatasetR\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2180aa0-a371-406e-945b-d503b129b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Теперь для PyTorch доступен только GPU 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d575839b-33a4-40bb-aaab-7a8576c4d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем доступность CUDA и количество GPU\n",
    "#если надо, можем переключиться на другую GPU\n",
    "if 0:\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:  # Если есть более 1 GPU\n",
    "            device = torch.device(\"cuda:1\")  # Явно указываем устройство 1\n",
    "            print(f\"Переключились на GPU 1\")\n",
    "        else:\n",
    "            print(\"Доступен только один GPU (номер 0), переключение невозможно\")\n",
    "    else:\n",
    "        print(\"CUDA недоступно\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e842ab-0145-4c24-91cf-af7473779856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638765cd-2449-4dee-905c-ac93167d697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#time.sleep(7*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e836de15-9520-40c7-9dd3-45390627e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_train = False#Запускаем ли мы сейчас обучение с нуля, или с какого-то чекпоинта\n",
    "\n",
    "\n",
    "bits_per_number = 4#Насколько сильно квантуем модель\n",
    "use_gguf = False#Можно использовать gguf\n",
    "gguf_folder_name = \"gguf_31\"#из этой папки\n",
    "\n",
    "\n",
    "cardinality = 128256#размер словаря токенов\n",
    "learnable_linear_model = False#учим ли мы линейную субмодель\n",
    "learnable_all = False#учим ли мы вообще весь трансформер (это очень тяжело по GPU-памяти, я не осилил)\n",
    "\n",
    "cfg_switch = 2\n",
    "if cfg_switch == 1:\n",
    "    #ЛЕГКОВЕСНЫЙ ТРАНСФОРМЕР\n",
    "    model_name = \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\"\n",
    "    architecture = 'B'\n",
    "    opt_type = 'adam'\n",
    "    mode = 'pretrain'#'finetune', 'pretrain'\n",
    "    #1.403\n",
    "else:\n",
    "    #ТЯЖЁЛЫЙ ТРАНСФОРМЕР\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "    architecture = 'N'#'L'\n",
    "    opt_type = 'adam'#'adam'\n",
    "    mode = 'finetune'\n",
    "\n",
    "\n",
    "tokenizer_name = model_name\n",
    "padding_token = 128009\n",
    "forbidden_tokens_list = [padding_token]\n",
    "seed = int(np.random.rand() * 1000000)#random seed for data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e6dc713-3f0b-42e2-b2ef-79a46038ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_memnets = True\n",
    "use_moe = False\n",
    "memnet_params = {}\n",
    "if model_name == \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\":\n",
    "    if architecture == 'A':\n",
    "        embedding_size = 2048#это просто свойство исходной сетки\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.0#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.05\n",
    "        conservativity = 0.05#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 1000#130#110#60#для дачала сделайте 2\n",
    "        lr = 1e-6#1e-3\n",
    "        \n",
    "        layer_configs = [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 1024, 1024, 1024, 1024, 1024, 512, 512, 512, 512, 512, 512, 512]#версия A\n",
    "        composition_size = 1#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 1.#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_A_composed.pth\"\n",
    "        max_tokens_in_loss = 1300#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "        batch_size = 3#2\n",
    "    elif architecture == 'B':\n",
    "        embedding_size = 2048#это просто свойство исходной сетки\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.5#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.05\n",
    "        conservativity = 0.05#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 100#130#110#60#для дачала сделайте 2\n",
    "        lr = 1e-6#1e-3\n",
    "        \n",
    "        layer_configs = [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 1024, 1024, 1024, 1024, 1024, 512, 512, 512, 512, 512, 512, 512]#версия A\n",
    "        composition_size = 16#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 1.#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_B_composed.pth\"\n",
    "        max_tokens_in_loss = 1300#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "        batch_size = 2#2\n",
    "        \n",
    "elif model_name == \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\":\n",
    "    embedding_size = 4096#это просто свойство исходной сетки\n",
    "\n",
    "    if architecture == 'D':\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.0#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.2\n",
    "        conservativity = 0.12#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 4200#60#для дачала сделайте 2\n",
    "        lr = 3e-6\n",
    "        \n",
    "        layer_configs = [1024, 512, 512, 512, 256, 256, 256, 256, 128, 128, 128, 128]#версия C\n",
    "        layer_configs = [2048, 1024, 1024, 512, 512, 512, 256, 256, 256, 256, 256, 256, 256, 256, 256]#версия D\n",
    "        composition_size = 1#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 1.#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_D_composed.pth\"\n",
    "        max_tokens_in_loss = 5500#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "    elif architecture == 'E':\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.0#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.05\n",
    "        conservativity = 0.15#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 2300#60#для дачала сделайте 2\n",
    "        lr = 1e-3\n",
    "        \n",
    "        layer_configs = [2048, 2048, 1024, 1024, 1024, 512, 512, 512, 512, 512, 512, 512, 256, 256, 256, 256]#версия E\n",
    "        composition_size = 1#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 1.#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_E_composed.pth\"\n",
    "        max_tokens_in_loss = 4000#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "    elif architecture == 'G':\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.0#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.025\n",
    "        conservativity = 0.07#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 5000#1400#12000#60#для дачала сделайте 2\n",
    "        #lr = 3e-7\n",
    "        lr = 1e-4\n",
    "        \n",
    "        layer_configs = [2048, 2048, 2048, 2048, 2048, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 512, 512, 512, 512, 512, 512]\n",
    "        composition_size = 1#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 1.#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_G_composed.pth\"\n",
    "        max_tokens_in_loss = 4000#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "    elif architecture == 'H':\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.0#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.025\n",
    "        conservativity = 0.11#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 1000#1400#12000#60#для дачала сделайте 2\n",
    "        #lr = 3e-7\n",
    "        lr = 1e-6\n",
    "        \n",
    "        layer_configs = [2048] * 5 + [1024] * 7\n",
    "        composition_size = 1#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 1.#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_H_composed.pth\"\n",
    "        max_tokens_in_loss = 2300#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "        use_memnets = True\n",
    "        memnet_params={'num_heads':12, 'query_size':64, 'num_key_values':320, 'value_size':256}\n",
    "    elif architecture == 'J':\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.0#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.025\n",
    "        conservativity = 0.12#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 800#1400#12000#60#для дачала сделайте 2\n",
    "        #lr = 3e-7\n",
    "        lr = 6e-7\n",
    "        \n",
    "        layer_configs = [1024 * 2] * 2 + [1024] * 8\n",
    "        composition_size = 2#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 1.#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_J_composed.pth\"\n",
    "        max_tokens_in_loss = 2300#1200#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "        use_memnets = True\n",
    "        memnet_params={'num_heads':8, 'query_size':64, 'num_key_values':300, 'value_size':256}\n",
    "\n",
    "    elif architecture == 'K':\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.0#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.025\n",
    "        conservativity = 0.12#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 800#1400#12000#60#для дачала сделайте 2\n",
    "        #lr = 3e-7\n",
    "        lr = 6e-7\n",
    "        \n",
    "        layer_configs = [1024 * 2] * 2 + [1024] * 8\n",
    "        composition_size = 2#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 1.#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_K_composed.pth\"\n",
    "        max_tokens_in_loss = 4000#1200#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "        use_memnets = True\n",
    "        memnet_params={'num_heads':8, 'query_size':64, 'num_key_values':300, 'value_size':256}\n",
    "\n",
    "    elif architecture == 'L':\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.0#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.025\n",
    "        conservativity = 0.08#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 700#1900#0#10000#1400#12000#60#для дачала сделайте 2\n",
    "        #lr = 3e-7\n",
    "        lr = 2e-6\n",
    "        #lr = 2e-5\n",
    "        \n",
    "        layer_configs = [1024 * 2] * 2 + [1024] * 8\n",
    "        composition_size = 1#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 1.#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_L_composed.pth\"\n",
    "        max_tokens_in_loss = 1200#1000#2000#1200#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "        use_memnets = False\n",
    "        memnet_params={'num_heads':8, 'query_size':64, 'num_key_values':300, 'value_size':256}\n",
    "\n",
    "    elif architecture == 'M':\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.0#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.03\n",
    "        conservativity = 0.15#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 400#600#800#400#270#230#450#1900#0#10000#1400#12000#60#для дачала сделайте 2\n",
    "        #lr = 3e-7\n",
    "        lr = 1e-6\n",
    "        \n",
    "        #layer_configs = [5000] + [4000] + [3200] + [2200] + [512] * 6\n",
    "        #layer_configs = [5000] + [4000] + [512] * 12\n",
    "        layer_configs = [320] * 1 + [160] * 1 + [64] * 6\n",
    "        composition_size = 27#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 0.8#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_M_composed.pth\"\n",
    "        max_tokens_in_loss = 40#170#250#2000#1200#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "        use_memnets = False\n",
    "        memnet_params={'num_heads':6, 'query_size':32, 'num_key_values':250, 'value_size':256}\n",
    "        start_train = False\n",
    "        \n",
    "        use_moe = True\n",
    "        router_layer_configs=[1024, 512, 256, 256, 256]\n",
    "        top_k = 6\n",
    "        inference_top_k = 6\n",
    "\n",
    "    elif architecture == 'N':\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        #сколько субмоделей выбрасывается из forward на обучении. Чем больше, тем лучше защита от оверфита. Если одна-две субмодели, net_dropout лучше занулять\n",
    "        net_dropout_rate = 0.0#если десятки субмоделей и хотим огромную защиту от оверфита, то это число надо проставлять в 0.9-0.95\n",
    "        #дропаут внутри субмоделей\n",
    "        individ_dropout_rate = 0.05\n",
    "        conservativity = 0.15#насколько сильно подавляем отклонение от старой стратегии\n",
    "        accum_batch = 310#600#800#400#270#230#450#1900#0#10000#1400#12000#60#для дачала сделайте 2\n",
    "        #lr = 3e-7\n",
    "        lr = 3e-7\n",
    "        \n",
    "        #layer_configs = [5000] + [4000] + [3200] + [2200] + [512] * 6\n",
    "        #layer_configs = [5000] + [4000] + [512] * 12\n",
    "        layer_configs = [320] * 1 + [160] * 2 + [64] * 7\n",
    "        composition_size = 25#число субмоделей класса ResNet. Чем больше их, тем больше или защита от оверфита (если большой net_dropout), или ёмкость\n",
    "        sample_features = 0.8#какая доля фичей приходит в субмодель. По дефолту ставится 0.4-0.6, но это если субмоделей как минимум 15. Сейчас их 1.\n",
    "        path2model = \"ern_model_N_composed.pth\"\n",
    "        max_tokens_in_loss = 60#20#170#250#2000#1200#сколько пар эмбеддинг-токен проходит через tail adapter за один forward\n",
    "        use_memnets = False\n",
    "        memnet_params={'num_heads':6, 'query_size':32, 'num_key_values':250, 'value_size':256}\n",
    "        start_train = False\n",
    "        \n",
    "        use_moe = True\n",
    "        router_layer_configs=[1024, 512, 256, 256, 256]\n",
    "        top_k = 7\n",
    "        inference_top_k = 6\n",
    "\n",
    "        \n",
    "\n",
    "    #я подобрал перебором это значение batch_size и accum_batch, именно при нём быстрее всего проходим батч размера 2000. Я не знаю, почему, но это так.\n",
    "    batch_size = 2\n",
    "\n",
    "    \n",
    "    if learnable_all:\n",
    "        #опасный и тормозной режим\n",
    "        batch_size = 2\n",
    "        layer_configs = [512, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e95f8f96-4254-4011-b5d8-6b9143009114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 2\n"
     ]
    }
   ],
   "source": [
    "#настройки датасета\n",
    "\n",
    "if mode == 'pretrain':\n",
    "    #претрейн\n",
    "    #max_seq_len = 11000\n",
    "    #max_seq_len4inference = 10950\n",
    "    # max_seq_len = 6900\n",
    "    # max_seq_len4inference = 6850\n",
    "    max_seq_len = 6500\n",
    "    max_seq_len4inference = 6450\n",
    "    # max_seq_len = 3800\n",
    "    # max_seq_len4inference = 3750\n",
    "    # max_seq_len = 3600\n",
    "    # max_seq_len4inference = 3550\n",
    "else:\n",
    "    #дообучение\n",
    "    # max_seq_len = 1950\n",
    "    # max_seq_len4inference = 1900\n",
    "    # max_seq_len = 2050\n",
    "    # max_seq_len4inference = 2000\n",
    "    max_seq_len = 9050\n",
    "    max_seq_len4inference = 9000\n",
    "\n",
    "print('batch_size', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbe92a99-e891-4af6-adc4-71b8faf0eaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27095857-2839-492d-a399-23877657f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:22: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:22: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\c'\n",
      "/tmp/ipykernel_2756843/2072397812.py:22: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  cache_dir=\"D:\\cache\\huggingface\\\\\"+ model_name)\n",
      "/tmp/ipykernel_2756843/2072397812.py:30: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  cache_dir=\"D:\\cache\\huggingface\\\\\"+ model_name)\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/ssdovgan/main/lib/python3.12/site-packages/transformers/quantizers/auto.py:186: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\")#, cache_dir=\"D:\\cache\\huggingface\\\\\"+ model_name)\n",
    "\n",
    "if bits_per_number == 4:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\"#, bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "elif bits_per_number == 8:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True, bnb_8bit_use_double_quant=True, bnb_8bit_quant_type=\"nf8\"#, bnb_8bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "else:\n",
    "    bnb_config = None\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "if learnable_all and not start_train:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "                  './last_modell',\n",
    "                  #device_map=\"auto\",\n",
    "                  #device_map=device,\n",
    "                  #torch_dtype=torch.bfloat16,\n",
    "                  quantization_config=bnb_config,\n",
    "                  cache_dir=\"D:\\cache\\huggingface\\\\\"+ model_name)\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "                  model_name,\n",
    "                  #device_map=\"auto\",\n",
    "                  #device_map=device,\n",
    "                  #torch_dtype=torch.bfloat16,\n",
    "                  quantization_config=bnb_config,\n",
    "                  cache_dir=\"D:\\cache\\huggingface\\\\\"+ model_name)\n",
    "if use_gguf:\n",
    "    model = PeftModelForCausalLM.from_pretrained(model, gguf_folder_name, load_in_4bit =True)\n",
    "    if isinstance(model, PeftModelForCausalLM):\n",
    "        model = model.merge_and_unload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d86cb70-956d-47c8-95b4-58d01131af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.lm_head\n",
    "torch.save(model.lm_head.weight, \"lin_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a99ede99-9df1-4630-a478-7875ceac40e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1538455"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание Dataset\n",
    "if mode == 'pretrain':\n",
    "    dataset = InstructDatasetR(\"../data_tea/dataset_llm_full_flat.pkl\", tokenizer, max_seq_len, cut=None)\n",
    "else:\n",
    "    dataset = InstructDatasetR(\"../data_tea/dataset_llm_full_instruct.pkl\", tokenizer, max_seq_len, cut=None)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1df0c1f2-4e8e-40b0-8428-a1cbc03564d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if start_train:\n",
    "    #создать модель\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "    if use_moe:\n",
    "        head = ensembles.MOE(input_size=embedding_size, \n",
    "                   out_size=cardinality, \n",
    "                   dropout_rate=individ_dropout_rate,\n",
    "                   layer_configs=layer_configs, \n",
    "                   use_sigmoid_end=False, \n",
    "                   use_batchnorm=True, \n",
    "                   use_activation=True, \n",
    "                   activation=nn.LeakyReLU(), \n",
    "                   sample_features=sample_features, \n",
    "                   initial_num_experts=composition_size,\n",
    "                   lin_bottleneck_size=None,\n",
    "                   lin_model_add=nn.Linear(embedding_size, cardinality).to(device),\n",
    "                   memnet_params=memnet_params,\n",
    "                   use_memnets=use_memnets,\n",
    "                   router_layer_configs=router_layer_configs,\n",
    "                   top_k=top_k,\n",
    "                   inference_top_k=inference_top_k,\n",
    "                   unlock_last_model=True)\n",
    "        head.inference_top_k = inference_top_k\n",
    "        head.top_k = top_k\n",
    "    else:\n",
    "        head = ensembles.EResNetPro(input_size=embedding_size, \n",
    "                   out_size=cardinality, \n",
    "                   net_dropout_rate=net_dropout_rate, \n",
    "                   individ_dropout_rate=individ_dropout_rate,\n",
    "                   layer_configs=layer_configs, \n",
    "                   use_sigmoid_end=False, \n",
    "                   use_batchnorm=True, \n",
    "                   use_activation=True, \n",
    "                   activation=nn.SiLU(),#nn.LeakyReLU(), \n",
    "                   sample_features=sample_features, \n",
    "                   composition_size=composition_size, \n",
    "                   lin_bottleneck_size=None,\n",
    "                   lin_model_add=nn.Linear(embedding_size, cardinality).to(device),\n",
    "                   memnet_params=memnet_params,\n",
    "                   use_memnets=use_memnets,\n",
    "                   exponential_layer_size=False)\n",
    "    head.submodels[-1].weight = torch.nn.Parameter(torch.load( \"lin_model.pth\").to(device).to(torch.float32))\n",
    "    head.submodels[-1].weight.requires_grad = learnable_linear_model\n",
    "else:\n",
    "    while 1:\n",
    "        try:\n",
    "            head = torch.load(path2model, weights_only=False, map_location=device)\n",
    "            break\n",
    "        except Exception:\n",
    "            import time\n",
    "            print(path2model, 'not loaded')\n",
    "            time.sleep(20)\n",
    "\n",
    "#собрать\n",
    "if learnable_all:\n",
    "    model.train()\n",
    "    for param in model.parameters():\n",
    "        try:\n",
    "            param.requires_grad = True\n",
    "            print('scss')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "else:\n",
    "    model.eval()\n",
    "head.train()\n",
    "head.to(device)\n",
    "head.by_submodels = True\n",
    "if opt_type == 'adam':\n",
    "    optimizer = torch.optim.Adam(head.parameters(), lr=lr)\n",
    "else:\n",
    "    momentum = 0.\n",
    "    optimizer = torch.optim.SGD(head.parameters(), lr=lr*0.06, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caa4456d-546a-44af-819d-33988e72d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_clip(tens, mn, mx):\n",
    "    mn = torch.tensor(mn).to(tens.device)\n",
    "    mx = torch.tensor(mx).to(tens.device)\n",
    "    tens[tens<mn] = torch.nn.Sigmoid()(tens[tens<mn]) + mn\n",
    "    tens[tens>mx] = torch.nn.Sigmoid()(tens[tens>mx]) + mx\n",
    "    return tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb00d1d3-eae1-49da-a838-9accd1e636e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fct = nn.CrossEntropyLoss(reduction = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "370c4e27-16c3-4121-bdc7-12401f445a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для подсчёта количества последних токенов, равных padding_token\n",
    "def count_padding(tensor, padding_token):\n",
    "    counts = []\n",
    "    for row in tensor:\n",
    "        count = 0\n",
    "        for token in reversed(row):\n",
    "            if token.item() == padding_token:\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "        counts.append(count)\n",
    "    return min(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1392464-c5c1-4c1f-8bba-0f10a03e3c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3515754341, 525336576)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sequential_models\n",
    "sequential_models.count_trainable_parameters(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db6d2511-4a48-43a8-9d7f-7917ec845bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet depth 44 depth2freeze 0\n"
     ]
    }
   ],
   "source": [
    "#заморозить первые N слоёв выходного резнета\n",
    "depth2freeze = 0#64\n",
    "print('resnet depth', len(head.submodels[0].layers), 'depth2freeze', depth2freeze)\n",
    "for i in range(len(head.submodels) - 1):\n",
    "    for l_num in range(len(head.submodels[0].layers)):\n",
    "        for p in head.submodels[i].layers[l_num].parameters():\n",
    "            p.requires_grad = l_num >= depth2freeze\n",
    "            #а какие не надо - не замораживать!\n",
    "\n",
    "# for l_num in range(depth2freeze + 2):\n",
    "#     for p in head.submodels[0].layers[l_num].parameters():\n",
    "#         print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e864e119-4808-41ec-a776-8e2f57048106",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_drop_idx = 0.04\n",
    "noise_coef = 0.04#0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a710644-e9e2-4b6a-b48f-04c07eaf147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2756843/2814761306.py:63: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  weights_full = torch.stack(weights_full).to(device).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss 1.539 loss_ampl_head 0.0426 620 from 1538455 0.0403 % acc 0.6553671559979839 2025-07-15 00:50:34.699037\n"
     ]
    }
   ],
   "source": [
    "#проинференсить модель на батчах, сделать датасет для постпроцессинга\n",
    "print('batch_size', batch_size)\n",
    "i_pointer = 0\n",
    "\n",
    "batch_accum_counter = 0\n",
    "loss_array = []\n",
    "metr_array = []\n",
    "while 1: \n",
    "    input_ids_full = []\n",
    "    labels_full = []\n",
    "    weights_full = []\n",
    "    #for i in range(batch_size):\n",
    "    i = 0\n",
    "    offset_counter = 0\n",
    "    while i < batch_size:\n",
    "        offset_counter += 1\n",
    "        sample_cur  = dataset[i_pointer + i]\n",
    "        input_ids = sample_cur['input_ids']\n",
    "        labels = sample_cur['labels']\n",
    "        weights = sample_cur['mult']\n",
    "\n",
    "        if labels.numel() < batch_size * 10:\n",
    "            #штраф на короткие строки для сокращения шума\n",
    "            weights *= 0.7\n",
    "        if labels.numel() < batch_size * 20:\n",
    "            #штраф на короткие строки для сокращения шума\n",
    "            weights *= 0.8\n",
    "        if labels.numel() < batch_size * 50:\n",
    "            #штраф на короткие строки для сокращения шума\n",
    "            weights *= 0.8\n",
    "        \n",
    "        input_ids_len = len(input_ids)\n",
    "        labels_len = len(labels)\n",
    "        input_ids = input_ids[input_ids!=padding_token]\n",
    "        \n",
    "        drop_idx = torch.rand_like(input_ids.to(torch.float)) < proba_drop_idx\n",
    "        input_ids = input_ids[~drop_idx]\n",
    "        \n",
    "        labels = labels[labels!=padding_token]\n",
    "        padding_size = input_ids_len + labels_len - len(input_ids) - len(labels)\n",
    "        input_ids_cur = torch.cat([input_ids, labels, torch.zeros(padding_size, dtype=torch.int32) + padding_token])[:max_seq_len4inference]\n",
    "        labels_cur = torch.cat([input_ids * 0 + padding_token, labels, torch.zeros(padding_size, dtype=torch.int32) + padding_token])[:max_seq_len4inference]\n",
    "        #print('fact_size', np.min([len(input_ids) + len(labels), max_seq_len4inference]), len(input_ids) + len(labels))\n",
    "        if torch.all(labels_cur) == padding_token:\n",
    "            print('empty label')\n",
    "            continue\n",
    "        i += 1\n",
    "        \n",
    "        input_ids_full.append(input_ids_cur[:-1])\n",
    "        labels_full.append(labels_cur[1:])\n",
    "        weights_full.append(weights)\n",
    "\n",
    "        # if not torch.any(input_ids!=0):\n",
    "        #     #X + Y\n",
    "        #     print(list(input_ids_cur.numpy()))\n",
    "        #     print(list(labels_cur.numpy()))\n",
    "        #     1/0\n",
    "    i_pointer += i #should be batch_size\n",
    "    #print('A', pd.Timestamp.now())\n",
    "    with torch.no_grad():\n",
    "        input_ids_full = torch.stack(input_ids_full).to(device)\n",
    "        labels_full = torch.stack(labels_full).to(device)\n",
    "        weights_full = torch.stack(weights_full).to(device).T\n",
    "\n",
    "        if 1:\n",
    "            cnt_pads = count_padding(labels_full, padding_token)\n",
    "            if cnt_pads >= input_ids_full.shape[1] - 5:\n",
    "                continue\n",
    "            if cnt_pads > 0:\n",
    "                input_ids_full = input_ids_full[:, :-cnt_pads]\n",
    "                labels_full = labels_full[:, :-cnt_pads]\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        #\n",
    "        #outp = model.forward(input_ids_full, attention_mask=None, labels=labels_full, token_type_ids=None, write_caches=False, read_caches=False, return_states=True)\n",
    "        # head.by_submodels = False\n",
    "        # head.training = False\n",
    "        # model.lm_head = head\n",
    "        # model.lm_head.half()\n",
    "        # outp = model.forward(input_ids_full, output_hidden_states=True, return_dict=False)\n",
    "\n",
    "        outp = model.forward(input_ids_full, output_hidden_states=True, return_dict=True)\n",
    "        outp['states'] = outp['hidden_states'][-1]\n",
    "    # {\"loss\": loss_agg, \"logits\": logits, \"states\":embeddings}\n",
    "        outp['states'] = outp['states'][:, :input_ids_full.shape[1]]\n",
    "        state_cur = outp['states'].reshape([outp['states'].shape[0] * outp['states'].shape[1], outp['states'].shape[2]])#.cpu().to(torch.float16).numpy()\n",
    "        state_cur += noise_coef * torch.std(state_cur) * torch.randn_like(state_cur)\n",
    "        weights_full2d = torch.vstack([weights_full] * labels_full.shape[-1]).to(device).T\n",
    "        labels_cur = labels_full.ravel()#.cpu().numpy()\n",
    "        weights_cur = weights_full2d.ravel()\n",
    "\n",
    "        del labels_full\n",
    "        del weights_full2d\n",
    "        del weights_full\n",
    "        del outp\n",
    "        idx = torch.isin(labels_cur, torch.tensor(forbidden_tokens_list).to(device))\n",
    "        labels_cur = labels_cur[~idx]\n",
    "        state_cur = state_cur[~idx]\n",
    "        weights_cur = weights_cur[~idx]\n",
    "        # if len(labels_cur) > max_tokens_in_loss:\n",
    "        #     indices = np.random.choice(len(labels_cur), size=max_tokens_in_loss, replace=False)\n",
    "        #     labels_cur = labels_cur[indices]\n",
    "        #     state_cur = state_cur[indices]\n",
    "    #print('B', pd.Timestamp.now())\n",
    "    if state_cur.shape[0] == 0:\n",
    "        continue\n",
    "    for x_start_pointer in range(0, state_cur.shape[0], max_tokens_in_loss): \n",
    "        logits, lst_logits = head(state_cur.to(torch.float32)[x_start_pointer: x_start_pointer + max_tokens_in_loss])\n",
    "        \n",
    "        ce_loss = loss_fct(logits, labels_cur[x_start_pointer: x_start_pointer + max_tokens_in_loss].view(-1))\n",
    "        ce_loss = ce_loss * weights_cur[x_start_pointer: x_start_pointer + max_tokens_in_loss].to(device)\n",
    "        ce_loss = soft_clip(ce_loss, -0.9, 10.)\n",
    "        loss_ampl_head = torch.nanmean(torch.abs(lst_logits[-1] - logits)) / (torch.std(lst_logits[-1]) + 1)\n",
    "        \n",
    "        loss = torch.nanmean(ce_loss) * (1./(conservativity + 1.)) + loss_ampl_head * (conservativity/(conservativity + 1.))\n",
    "        loss.backward()\n",
    "        l = len(lst_logits)\n",
    "        for j in range(l - 1, -1, -1):\n",
    "            del lst_logits[j]\n",
    "        #print('-C', pd.Timestamp.now())\n",
    "        #del lst_logits\n",
    "    del state_cur\n",
    "    #print('D', pd.Timestamp.now())\n",
    "\n",
    "    acc = torch.mean((torch.argmax(logits, axis=-1) == labels_cur[x_start_pointer: x_start_pointer + max_tokens_in_loss]).to(torch.float16))\n",
    "    del logits\n",
    "    del labels_cur\n",
    "    batch_accum_counter += 1\n",
    "    loss_array += [torch.mean(ce_loss).item()]\n",
    "    metr_array += [acc.item()]\n",
    "    if batch_accum_counter >= accum_batch:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        torch.cuda.empty_cache()\n",
    "        print('ce_loss', np.round(np.mean(loss_array), 3), 'loss_ampl_head', np.round(loss_ampl_head.item(), 4), i_pointer, 'from', len(dataset), np.round(100 * i_pointer/len(dataset), 5), '%', 'acc', np.mean(metr_array), pd.Timestamp.now())\n",
    "        loss_array = []\n",
    "        metr_array = []\n",
    "        batch_accum_counter = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        if (np.random.rand() < 1 and accum_batch > 100) or (np.random.rand() < 0.1 and accum_batch <= 100):\n",
    "            head.training = False\n",
    "            torch.save(head, path2model)\n",
    "            if np.random.rand()<0.2:\n",
    "                torch.save(head, path2model + '.back')\n",
    "            head.training = True\n",
    "            if learnable_all:\n",
    "                model.eval()\n",
    "                model.save_pretrained(\"./last_modell\")\n",
    "                model.train()\n",
    "                for param in model.parameters():\n",
    "                    try:\n",
    "                        param.requires_grad = True\n",
    "                    except Exception as e:\n",
    "                        pass \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bfa71b-f539-4680-ba9f-8a401eca735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.5 секунд на строку в среднем, длина 4200, adam\n",
    "#2 сек на строку длины 3800 с adam\n",
    "#0.8 сек на строку длины 3800, sgd без momentum (?!)\n",
    "# сек на строку длины 4200, sgd без momentum\n",
    "#2 сек на строку длины 3600 с adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33797a51-0dc6-40f7-be53-55ef72a755c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2634e-e8bc-4c32-8d53-60685f0e98d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#если принудительно стопнули, можно добить батч\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "torch.cuda.empty_cache()\n",
    "print('ce_loss', np.round(np.mean(loss_array), 3), 'loss_ampl_head', np.round(loss_ampl_head.item(), 4), i_pointer, 'from', len(dataset), np.round(100 * i_pointer/len(dataset), 5), '%', 'acc', np.mean(metr_array), pd.Timestamp.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cefa2d-1085-4616-a6a6-4a25ea2c6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохранение tail adapter-а вручную\n",
    "head.training = False\n",
    "head.by_submodels = False\n",
    "torch.save(head, path2model)\n",
    "\n",
    "if learnable_all:\n",
    "    model.eval()\n",
    "    model.save_pretrained(\"./last_modell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e8065-14b3-4c53-8389-de01df85aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51428eb-1bbd-4d89-9e7e-3f890b37b841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
